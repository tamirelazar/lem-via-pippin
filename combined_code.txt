
##### my_digital_being/framework/activity_decorator.py #####
import functools
import logging
from typing import Callable, Any, Dict, List, Optional
from datetime import datetime
import json

logger = logging.getLogger(__name__)


def activity(
    name: str,
    energy_cost: float = 0.2,
    cooldown: int = 0,
    required_skills: Optional[List[str]] = None,
):
    """Decorator for activity classes."""

    def decorator(cls):
        cls.activity_name = name
        cls.energy_cost = energy_cost
        cls.cooldown = cooldown
        cls.required_skills = required_skills or []
        cls.last_execution = None

        # Add metadata to the class
        cls.metadata = {
            "name": name,
            "energy_cost": energy_cost,
            "cooldown": cooldown,
            "required_skills": required_skills,
        }

        # Wrap the execute method
        original_execute = cls.execute

        @functools.wraps(original_execute)
        async def wrapped_execute(self, *args, **kwargs):
            try:
                # Pre-execution checks
                if not self._can_execute():
                    logger.warning(f"Activity {name} is on cooldown")
                    return ActivityResult(
                        success=False, error="Activity is on cooldown"
                    )

                # Log activity start
                logger.info(f"Starting activity: {name}")
                start_time = datetime.now()

                # Execute the activity
                result = await original_execute(self, *args, **kwargs)

                # Post-execution processing
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                cls.last_execution = end_time

                # Log activity completion
                logger.info(f"Completed activity: {name} in {duration:.2f} seconds")

                return result

            except Exception as e:
                logger.error(f"Error in activity {name}: {e}")
                return ActivityResult(success=False, error=str(e))

        cls.execute = wrapped_execute
        return cls

    return decorator


class ActivityResult:
    """Class to store activity execution results."""

    def __init__(
        self,
        success: bool,
        data: Optional[Any] = None,
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ):
        self.success = success
        self.data = data
        self.error = error
        self.metadata = metadata or {}
        self.timestamp = datetime.now()

    def to_dict(self) -> Dict[str, Any]:
        """Convert result to dictionary format."""
        data_dict = {}
        if self.data:
            if hasattr(self.data, "to_dict"):
                data_dict = self.data.to_dict()
            elif isinstance(self.data, dict):
                data_dict = self.data
            else:
                try:
                    data_dict = json.loads(json.dumps(self.data))
                except:
                    data_dict = str(self.data)

        return {
            "success": self.success,
            "data": data_dict,
            "error": self.error,
            "metadata": self.metadata,
            "timestamp": self.timestamp.isoformat(),
        }

    @classmethod
    def success_result(
        cls, data: Optional[Any] = None, metadata: Optional[Dict[str, Any]] = None
    ):
        """Create a successful result."""
        return cls(success=True, data=data, metadata=metadata)

    @classmethod
    def error_result(cls, error: str, metadata: Optional[Dict[str, Any]] = None):
        """Create an error result."""
        return cls(success=False, error=error, metadata=metadata)


class ActivityBase:
    """Base class for all activities."""

    def __init__(self):
        self.result = None
        self.last_execution: Optional[datetime] = None
        self.cooldown: int = 0

    def _can_execute(self) -> bool:
        """Check if the activity can be executed."""
        if self.last_execution is None:
            return True

        now = datetime.now()
        time_since_last = (now - self.last_execution).total_seconds()
        return time_since_last >= self.cooldown

    def get_result(self) -> Dict[str, Any]:
        """Get the result of the activity execution."""
        if isinstance(self.result, ActivityResult):
            return self.result.to_dict()
        return {
            "success": bool(self.result),
            "data": self.result if self.result else None,
            "error": None,
            "timestamp": datetime.now().isoformat(),
        }

    async def execute(self, shared_data) -> ActivityResult:
        """Base execute method that should be overridden by activities."""
        raise NotImplementedError("Activities must implement execute method")


def skill_required(skill_name: str):
    """Decorator to specify required skills for methods."""

    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            if not hasattr(self, "required_skills"):
                self.required_skills = []
            if skill_name not in self.required_skills:
                self.required_skills.append(skill_name)
            return func(self, *args, **kwargs)

        return wrapper

    return decorator


##### my_digital_being/framework/activity_loader.py #####
import importlib
import logging
import re
from pathlib import Path
from typing import Dict, Type, Any, Optional

logger = logging.getLogger(__name__)


def read_activity_code(activity_name: str) -> Optional[str]:
    """
    Reads the .py file from 'activities/' by the given filename (e.g. 'activity_tweet.py').
    Returns its text content or None if file not found.
    """
    activity_file = Path(__file__).parent.parent / "activities" / activity_name
    if not activity_file.exists():
        logger.warning(f"read_activity_code: File not found: {activity_file}")
        return None
    return activity_file.read_text()


def write_activity_code(activity_name: str, new_code: str) -> bool:
    """
    Writes 'new_code' into the .py file in 'activities/' with the given filename.
    Returns True on success, False on error.
    """
    activity_file = Path(__file__).parent.parent / "activities" / activity_name
    try:
        activity_file.write_text(new_code, encoding="utf-8")
        return True
    except Exception as e:
        logger.error(f"write_activity_code: Failed to write {activity_file}: {e}")
        return False


class ActivityLoader:
    def __init__(self, activities_path: str = None, config: dict = None):
        """
        :param activities_path: Where activity_*.py files live.
        :param config: The main config object from being.configs (used to skip disabled).
        """
        if activities_path is None:
            activities_path = Path(__file__).parent.parent / "activities"
        self.activities_path = Path(activities_path)

        # [ADDED] We'll read 'activities_config' from config
        self.activities_config = {}
        if config:
            self.activities_config = config.get("activity_constraints", {}).get(
                "activities_config", {}
            )

        self.loaded_activities: Dict[str, Type[Any]] = {}
        logger.info(f"ActivityLoader initialized with path: {self.activities_path}")

    def load_activities(self):
        """Load all activities from the activities directory."""
        if not self.activities_path.exists():
            logger.error(f"Activities directory not found: {self.activities_path}")
            return

        logger.info(f"Starting to load activities from: {self.activities_path}")
        for activity_file in self.activities_path.glob("activity_*.py"):
            try:
                logger.info(f"Found activity file: {activity_file}")
                file_text = activity_file.read_text()

                # We expect a pattern like: class SomeActivity(ActivityBase):
                class_match = re.search(
                    r"class\s+(\w+)\(.*ActivityBase.*\):", file_text
                )
                if not class_match:
                    logger.error(f"No recognized activity class in {activity_file}")
                    continue

                class_name = class_match.group(1)
                module_name = activity_file.stem  # e.g. "activity_draw"

                # Possibly skip if "enabled": false in activities_config
                activity_cfg = None
                if class_name in self.activities_config:
                    activity_cfg = self.activities_config[class_name]
                elif module_name in self.activities_config:
                    activity_cfg = self.activities_config[module_name]

                if activity_cfg and (activity_cfg.get("enabled") is False):
                    logger.info(
                        f"Activity {class_name} is disabled by config, skipping load."
                    )
                    continue

                spec = importlib.util.spec_from_file_location(
                    module_name, activity_file
                )
                if spec and spec.loader:
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)

                    activity_class = getattr(module, class_name)
                    self.loaded_activities[module_name] = activity_class
                    logger.info(
                        f"Successfully loaded activity {module_name} -> class {class_name}"
                    )

            except Exception as e:
                logger.error(
                    f"Failed to load activity {activity_file}: {str(e)}", exc_info=True
                )

    def get_activity(self, activity_name: str) -> Optional[Type[Any]]:
        """Get an activity class by module name (e.g. 'activity_tweet')."""
        return self.loaded_activities.get(activity_name)

    def get_all_activities(self) -> Dict[str, Type[Any]]:
        """Get all loaded activities (module_name -> class)."""
        return self.loaded_activities.copy()

    def reload_activities(self):
        """Reload all activities by clearing and reloading."""
        self.loaded_activities.clear()
        self.load_activities()


##### my_digital_being/framework/activity_selector.py #####
import logging
import random
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class ActivitySelector:
    def __init__(self, constraints: Dict[str, Any], state):
        """
        :param constraints: A dictionary that typically includes:
            {
              "activity_cooldowns": { ... },  # No longer used
              "activity_requirements": { ... },
              "activities_config": { "DrawActivity": {"enabled": false}, ... }
            }
        :param state: The DigitalBeing's State object, used to check mood, energy, etc.
        """
        self.constraints = constraints
        self.state = state

        # Tracks the last time each activity class was executed
        self.last_activity_times: Dict[str, datetime] = {}

        # The loader is not set until set_activity_loader() is called
        self.activity_loader = None

    def get_activity_class(self, activity_key: str):
        """
        Get an activity class by its module name (e.g. 'activity_draw') or class name (e.g. 'DrawActivity').
        Returns None if not found.
        """
        if not self.activity_loader:
            logger.error("Activity loader not set; cannot get activity class.")
            return None

        # First try to get it directly by module name
        activity_class = self.activity_loader.get_activity(activity_key)
        if activity_class:
            return activity_class

        # If not found, try to find it by class name
        all_activities = self.activity_loader.get_all_activities()
        for module_name, cls in all_activities.items():
            if cls.__name__ == activity_key:
                return cls

        return None

    def set_activity_loader(self, loader):
        """
        Attach an ActivityLoader instance to this ActivitySelector.
        That loader has the loaded_activities dictionary (module_name -> activity_class).
        """
        self.activity_loader = loader
        logger.info("Activity loader set in selector")

    def select_next_activity(self):
        """
        Main entry point:
        1. Gather all available activities (not on cooldown, not disabled).
        2. Filter them by additional requirements like energy, skill requirements, etc.
        3. Use personality to pick one at random (weighted).
        4. Record the time we picked it.
        5. Return the activity instance or None.
        """
        if not self.activity_loader:
            logger.error("Activity loader not set; cannot select activity.")
            return None

        # Step 1: get all activities that are not on cooldown and are enabled
        available_activities = self._get_available_activities()
        if not available_activities:
            next_available = self.get_next_available_times()
            logger.info(
                f"No activities available at this time. Next available activities: {next_available}"
            )
            return None

        # Step 2: filter out ones that fail "energy" or "activity_requirements"
        suitable_activities = []
        for activity in available_activities:
            activity_name = activity.__class__.__name__
            if self._check_energy_requirements(
                activity
            ) and self._check_activity_requirements(activity_name):
                logger.info(f"Activity {activity_name} is suitable for execution.")
                suitable_activities.append(activity)
            else:
                logger.info(f"Activity {activity_name} does not meet requirements.")

        if not suitable_activities:
            logger.info("No activities suitable for current state.")
            return None

        # Step 3: personality-based selection
        # (If you have a "personality" dict in state, else use {}.)
        personality = self.state.get_current_state().get("personality", {})
        selected_activity = self._select_based_on_personality(
            suitable_activities, personality
        )

        if selected_activity:
            chosen_name = selected_activity.__class__.__name__
            logger.info(f"Selected activity: {chosen_name}")
            # Step 4: record the time we picked it
            self.last_activity_times[chosen_name] = datetime.now()

        return selected_activity

    def get_next_available_times(self) -> List[Dict[str, Any]]:
        """
        Provide info on when each loaded activity class will be available again.
        This is mostly for debugging/logging: "You can next run DrawActivity in 1.5 hours", etc.
        We now use the activity's decorator-based cooldown.
        """
        current_time = datetime.now()
        next_available = []

        all_activities = self.activity_loader.get_all_activities()

        for activity_name, activity_class in all_activities.items():
            base_name = activity_class.__name__

            # Pull cooldown from the class (decorator)
            cooldown = getattr(activity_class, "cooldown", 0)
            last_time = self.last_activity_times.get(base_name)

            if last_time:
                time_since_last = (current_time - last_time).total_seconds()
                time_remaining = max(0, cooldown - time_since_last)
                next_time = current_time + timedelta(seconds=time_remaining)

                next_available.append(
                    {
                        "activity": base_name,
                        "available_in_seconds": time_remaining,
                        "next_available_at": next_time.strftime("%Y-%m-%d %H:%M:%S"),
                        "cooldown_period": cooldown,
                    }
                )
            else:
                # never run before => it's available now
                next_available.append(
                    {
                        "activity": base_name,
                        "available_in_seconds": 0,
                        "next_available_at": "Now",
                        "cooldown_period": cooldown,
                    }
                )

        # sort by soonest availability
        return sorted(next_available, key=lambda x: x["available_in_seconds"])

    def _get_available_activities(self) -> List[Any]:
        """
        Return a list of *activity instances* that:
          1) Are loaded by the ActivityLoader
          2) Are "enabled" in the config
          3) Are not on cooldown (based on the activity's own decorator-based cooldown)
        Then the caller can further filter them for energy or skill requirements.
        """
        available = []
        current_time = datetime.now()

        all_activities = self.activity_loader.get_all_activities()
        activities_config = self.constraints.get("activities_config", {})

        for module_name, activity_class in all_activities.items():
            base_name = activity_class.__name__

            # 1) skip if disabled
            if base_name in activities_config:
                if activities_config[base_name].get("enabled", True) is False:
                    logger.info(f"Skipping disabled activity: {base_name}")
                    continue

            # 2) check if it's on cooldown
            cooldown = getattr(activity_class, "cooldown", 0)
            last_time = self.last_activity_times.get(base_name)
            if last_time:
                time_since_last = (current_time - last_time).total_seconds()
                if time_since_last < cooldown:
                    logger.info(
                        f"{base_name} still on cooldown for {cooldown - time_since_last:.1f}s more."
                    )
                    continue

            # If we get here, the activity is enabled & not on cooldown
            try:
                instance = activity_class()
                logger.info(f"Created instance of {base_name} successfully.")
                available.append(instance)
            except Exception as e:
                logger.error(
                    f"Failed to create instance of {base_name}: {e}", exc_info=True
                )

        return available

    def _check_activity_requirements(self, activity_name: str) -> bool:
        """
        Check constraints['activity_requirements'][activity_name] if you need logic
        for required skills or memory usage. Currently returns True to accept all.
        """
        requirements = self.constraints.get("activity_requirements", {}).get(
            activity_name, {}
        )
        logger.debug(f"Checking requirements for {activity_name}: {requirements}")
        return True

    def _check_energy_requirements(self, activity) -> bool:
        """
        Check if the being has enough energy for the activity (activity.energy_cost).
        """
        current_energy = self.state.get_current_state().get("energy", 1.0)
        required_energy = getattr(activity, "energy_cost", 0.2)
        has_energy = current_energy >= required_energy

        if not has_energy:
            logger.info(
                f"Insufficient energy for {activity.__class__.__name__} "
                f"(required={required_energy}, current={current_energy})."
            )
        return has_energy

    def _select_based_on_personality(
        self, activities: List[Any], personality: Dict[str, float]
    ) -> Optional[Any]:
        """
        Given a list of candidate activity instances, choose one with a weighted random approach.
        """
        if not activities:
            return None

        weights = []
        for activity in activities:
            weight = 1.0
            if hasattr(activity, "creativity_factor"):
                weight *= (
                    1 + personality.get("creativity", 0.5) * activity.creativity_factor
                )
            if hasattr(activity, "social_factor"):
                weight *= (
                    1 + personality.get("friendliness", 0.5) * activity.social_factor
                )
            weights.append(weight)

        chosen = random.choices(activities, weights=weights, k=1)[0]
        return chosen


##### my_digital_being/framework/api_key_setup.py #####
"""Tool for securely setting up API keys."""

import logging
from typing import List, Dict, Tuple
import os
from .secret_storage import secret_manager

logger = logging.getLogger(__name__)


class APIKeySetup:
    """Manages the setup and validation of API keys for skills."""

    @staticmethod
    async def setup_keys(skill_name: str, required_keys: List[str]) -> Dict[str, bool]:
        """
        Set up API keys for a skill using the configured secret storage.

        Args:
            skill_name: Name of the skill requiring API keys
            required_keys: List of required API key names

        Returns:
            Dictionary mapping key names to setup success status
        """
        results = {}

        try:
            # For Replit environment, use ask_secrets
            if "REPL_ID" in os.environ:
                from replit import ask_secrets

                env_keys = [
                    f"{skill_name.upper()}_{key.upper()}_API_KEY"
                    for key in required_keys
                ]

                await ask_secrets(
                    secret_keys=env_keys,
                    user_message=f"""
The {skill_name} skill requires the following API keys to function:
{', '.join(required_keys)}

Please provide these keys to enable the skill's functionality.
These will be stored securely as environment variables.
""",
                )

            # Verify keys were set properly
            for key in required_keys:
                exists = await secret_manager.check_api_key_exists(skill_name, key)
                results[key] = exists

                if exists:
                    logger.info(f"Successfully set up {key} API key for {skill_name}")
                else:
                    logger.warning(f"Failed to set up {key} API key for {skill_name}")

        except Exception as e:
            logger.error(f"Error setting up API keys for {skill_name}: {e}")
            for key in required_keys:
                results[key] = False

        return results

    @staticmethod
    async def check_skill_keys(
        skill_name: str, required_keys: List[str]
    ) -> Tuple[bool, List[str]]:
        """
        Check if a skill has all required API keys configured.

        Args:
            skill_name: Name of the skill to test
            required_keys: List of required API keys

        Returns:
            Tuple of (success, list of missing keys)
        """
        missing_keys = []
        for key in required_keys:
            exists = await secret_manager.check_api_key_exists(skill_name, key)
            if not exists:
                missing_keys.append(key)

        return len(missing_keys) == 0, missing_keys

    @staticmethod
    async def list_skill_requirements(skill_requirements: Dict[str, List[str]]) -> str:
        """
        Get a formatted string of all skills and their API key requirements.

        Args:
            skill_requirements: Dictionary mapping skill names to their required keys

        Returns:
            Formatted string showing all skills and their required API keys
        """
        if not skill_requirements:
            return "No skills with API key requirements registered."

        output = ["Skill API Key Requirements:"]
        for skill, keys in skill_requirements.items():
            success, missing = await APIKeySetup.check_skill_keys(skill, keys)
            status = "✓" if success else "✗"
            output.append(f"\n{status} {skill}:")
            for key in keys:
                exists = await secret_manager.check_api_key_exists(skill, key)
                configured = "✓" if exists else "✗"
                output.append(f"  {configured} {key}")

        return "\n".join(output)


##### my_digital_being/framework/api_management.py #####
"""
Unified API key management system with flexible storage backends.
Implements:
 - get_skill_status -> returns any "required_keys"
 - get_composio_integrations -> calls composio_manager.list_available_integrations()
 - set_api_key -> if you want to store them
"""

import logging
from typing import Dict, Any, Optional, Set, List

from .secret_storage import secret_manager
from .composio_integration import composio_manager

logger = logging.getLogger(__name__)


class APIManager:
    def __init__(self):
        # Example: track required keys for each skill
        self._required_keys: Dict[str, Set[str]] = {}
        self._secret_manager = secret_manager
        self._composio_manager = composio_manager
        logger.info("Initialized API Manager with Composio integration")

    @property
    def composio_manager(self):
        return self._composio_manager

    def register_required_keys(self, skill_name: str, required_keys: List[str]) -> bool:
        """
        Register that a given skill_name requires the specified list of key names (e.g. ["OPENAI"]).
        """
        if not skill_name or not required_keys:
            return False
        self._required_keys[skill_name] = set(required_keys)
        logger.info(f"Registered keys for skill {skill_name}: {required_keys}")
        return True

    def get_required_keys(
        self, skill_name: Optional[str] = None
    ) -> Dict[str, List[str]]:
        """
        Return a dict of skill -> list of required keys.
        If skill_name is provided, return only that one skill's key list.
        """
        if skill_name:
            # Return just one skill's keys if it exists
            if skill_name in self._required_keys:
                return {skill_name: list(self._required_keys[skill_name])}
            else:
                return {skill_name: []}
        else:
            # Return all
            return {skill: list(keys) for skill, keys in self._required_keys.items()}

    async def check_api_key_exists(self, skill_name: str, key_name: str) -> bool:
        """
        Pass-through to secret_manager to check if a key is set.
        This is used in e.g. ImageGenerationSkill or other activities that do:
        `await api_manager.check_api_key_exists(...).`
        """
        return await self._secret_manager.check_api_key_exists(skill_name, key_name)

    async def get_api_key(self, skill_name: str, key_name: str) -> Optional[str]:
        """
        Return the actual API key string from secret_manager.
        Called by skill_chat.py's initialize() or skill_generate_image.py, etc.
        """
        return await self._secret_manager.get_api_key(skill_name, key_name)

    async def get_skill_status(self) -> Dict[str, Any]:
        """
        Example: For each skill, show which keys are configured or not.
        """
        skills_status = {}
        for skill, keys in self._required_keys.items():
            skill_info = {"display_name": skill.title(), "required_keys": {}}
            for k in keys:
                # Check if configured
                exists = await self._secret_manager.check_api_key_exists(skill, k)
                skill_info["required_keys"][k] = bool(exists)
            skills_status[skill] = skill_info
        return skills_status

    async def set_api_key(
        self, skill_name: str, key_name: str, value: str
    ) -> Dict[str, Any]:
        """
        Store a new API key into secret_manager for a given skill & key name.
        """
        success = await self._secret_manager.set_api_key(skill_name, key_name, value)
        return {"success": success, "affected_skills": {}}

    async def get_composio_integrations(self) -> List[Dict[str, Any]]:
        """
        Ask the ComposioManager for the available integrations (connected or not).
        """
        return await self._composio_manager.list_available_integrations()

    async def list_actions_for_app(self, app_name: str) -> Dict[str, Any]:
        """
        Calls composio_manager.list_actions_for_app(app_name).
        """
        return await self._composio_manager.list_actions_for_app(app_name)

    async def get_auth_schemes(self, app_name: str) -> Dict[str, Any]:
        """Get available authentication schemes for an app."""
        return await self._composio_manager.get_auth_schemes(app_name)

    async def initiate_api_key_connection(
        self, app_name: str, api_key: str
    ) -> Dict[str, Any]:
        """Initiate a connection using API key authentication."""
        return await self._composio_manager.initiate_api_key_connection(
            app_name, api_key
        )


# Global
api_manager = APIManager()


##### my_digital_being/framework/composio_integration.py #####
"""
Composio integration module for managing OAuth flows and dynamic tool integration.
Implements:
 - handle_oauth_callback(...) to finalize the connection
 - store a connected indicator in _oauth_connections
 - list_available_integrations() returns "connected": True if we have that.
 - list_actions_for_app(...) returns the app's actions by calling Composio's API directly

[ADDED] We now persist these connections in ./storage/composio_oauth.json
"""

import os
import logging
import json
from pathlib import Path
from typing import Dict, Any, List

import requests  # Used for the direct Composio API call

from .secret_storage import secret_manager
from composio_openai import ComposioToolSet

logger = logging.getLogger(__name__)


class ComposioManager:
    def __init__(self):
        self._toolset = None
        self._entity_id = "MyDigitalBeing"
        self._oauth_connections: Dict[str, Dict[str, Any]] = {}
        self._available_apps: Dict[str, Any] = {}

        # [ADDED] We store the OAuth connections in a JSON file
        self.storage_file = Path("./storage/composio_oauth.json")

        logger.info("Starting Composio integration initialization...")

        # Load persisted OAuth connections if any
        self._load_persistence()

        # Initialize the Composio toolset
        self._initialize_toolset()

    # [ADDED] Load connections from disk
    def _load_persistence(self):
        if self.storage_file.exists():
            try:
                with self.storage_file.open("r", encoding="utf-8") as f:
                    self._oauth_connections = json.load(f)
                logger.info(
                    f"Loaded Composio OAuth connections from {self.storage_file}"
                )
            except Exception as e:
                logger.warning(f"Error loading Composio OAuth file: {e}")
        else:
            logger.info("No existing Composio OAuth file found.")

    # [ADDED] Save connections to disk
    def _save_persistence(self):
        try:
            self.storage_file.parent.mkdir(exist_ok=True)
            with self.storage_file.open("w", encoding="utf-8") as f:
                json.dump(self._oauth_connections, f, indent=2)
            logger.info("Saved Composio OAuth connections to disk.")
        except Exception as e:
            logger.error(f"Failed to save Composio OAuth connections: {e}")

    def _initialize_toolset(self):
        try:
            api_key = os.environ.get("COMPOSIO_API_KEY")
            if not api_key:
                logger.error("No COMPOSIO_API_KEY in environment")
                return
            self._toolset = ComposioToolSet(api_key=api_key, entity_id=self._entity_id)
            logger.info("Created ComposioToolSet instance")

            # Load the list of apps
            tools = self._toolset.get_tools(actions=["COMPOSIO_LIST_APPS"])
            result = self._toolset.execute_action(
                action="COMPOSIO_LIST_APPS", params={}, entity_id=self._entity_id
            )
            success_value = result.get("success") or result.get("successfull")
            if success_value:
                apps_data = result.get("data", {})
                apps_list = apps_data.get("apps", [])
                for app_info in apps_list:
                    key = app_info.get("key", "").upper()
                    if key:
                        self._available_apps[key] = app_info
                logger.info(
                    f"Fetched {len(self._available_apps)} apps from Composio meta-app"
                )
            else:
                logger.warning("COMPOSIO_LIST_APPS action failed.")
        except Exception as e:
            logger.error(f"Error init Composio: {e}", exc_info=True)
            self._available_apps = {}

    def mark_app_connected(self, app_name: str, connection_id: str):
        """Utility to mark an app as connected in our local _oauth_connections dict."""
        upper_app = app_name.upper()
        self._oauth_connections[upper_app] = {
            "connected": True,
            "connection_id": connection_id,
        }
        logger.info(
            f"mark_app_connected: Marked {upper_app} as connected with connection_id={connection_id}"
        )

        # [ADDED] Persist updated connections to disk
        self._save_persistence()

    async def initiate_oauth_flow(
        self, app_name: str, redirect_url: str
    ) -> Dict[str, Any]:
        """Begin an OAuth connection for a given app."""
        if not self._toolset:
            return {"success": False, "error": "Toolset not initialized"}

        try:
            upper_app = app_name.upper()
            app_info = self._available_apps.get(upper_app)
            if not app_info:
                return {"success": False, "error": f"Unknown app: {app_name}"}

            # Check if OAuth is supported
            auth_schemes = self._toolset.get_auth_schemes(app=app_info["key"])
            auth_modes = [scheme.auth_mode for scheme in auth_schemes]
            if "OAUTH2" not in auth_modes and "OAUTH1" not in auth_modes:
                return {
                    "success": False,
                    "error": "OAuth is not supported for this app",
                }

            logger.info(f"Initiating OAuth flow for {app_name}")
            connection_req = self._toolset.initiate_connection(
                redirect_url=redirect_url,
                entity_id=self._entity_id,
                app=app_info["key"],
                auth_scheme=auth_modes[0],
            )

            conn_id = getattr(connection_req, "connectionId", None)
            if not conn_id:
                conn_id = getattr(connection_req, "connectedAccountId", None)
            if not conn_id:
                return {"success": False, "error": "Failed to get connection ID"}

            return {
                "success": True,
                "redirect_url": connection_req.redirectUrl,
                "connection_id": conn_id,
            }
        except Exception as e:
            logger.error(
                f"initiate_oauth_flow error for {app_name}: {e}", exc_info=True
            )
            return {"success": False, "error": str(e)}

    async def handle_oauth_callback(
        self, connection_id: str, code: str
    ) -> Dict[str, Any]:
        """
        Finalize the OAuth flow for a given connection_id using the code from the provider.
        Then store 'connected' in _oauth_connections so our front-end can see that it's connected.
        """
        if not self._toolset:
            return {"success": False, "error": "Toolset not initialized"}

        try:
            result = self._toolset.complete_connection(
                connection_id=connection_id, code=code
            )
            if result.success:
                # Mark as connected
                app_key = result.app.upper() if result.app else "UNKNOWN"
                self.mark_app_connected(app_key, connection_id)
                logger.info(f"handle_oauth_callback: Marked {app_key} as connected.")
            else:
                logger.warning(f"handle_oauth_callback: success=False for {result.app}")

            return {
                "success": result.success,
                "app": result.app,
                "message": (
                    "Connection successful" if result.success else "Connection failed"
                ),
            }
        except Exception as e:
            logger.error(f"Error in handle_oauth_callback: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    def mark_app_connected_without_code(self, app_name: str, connected_account_id: str):
        """
        If Composio doesn't require .complete_connection for some flows
        but returns connectedAccountId in the callback,
        we can directly mark the app as connected.
        """
        self.mark_app_connected(app_name, connected_account_id)

    async def list_available_integrations(self) -> List[Dict[str, Any]]:
        """
        Return a list of all apps from _available_apps,
        with "connected" = True if we've tracked them in _oauth_connections.
        """
        results = []
        for key, info in self._available_apps.items():
            upper_key = key.upper()
            is_connected = False
            if upper_key in self._oauth_connections and self._oauth_connections[
                upper_key
            ].get("connected"):
                is_connected = True

            results.append(
                {
                    "name": upper_key,  # e.g. "TWITTER"
                    "display_name": info.get("name", upper_key),
                    "connected": is_connected,
                    "oauth_supported": True,
                }
            )
        return results

    async def list_actions_for_app(self, app_name: str) -> Dict[str, Any]:
        """
        Returns a structure with all possible Composio actions for the given app_name,
        using a direct GET call to Composio's /api/v2/actions/list/all endpoint.

        Example return structure:
        {
            "success": True,
            "actions": [
                "TWITTER_TWEET_CREATE",
                "TWITTER_DM_SEND",
                ...
            ]
        }
        """
        upper_app = app_name.upper()

        # Check if the app is recognized in our local cache
        if upper_app not in self._available_apps:
            return {
                "success": False,
                "error": f"App '{app_name}' not recognized in _available_apps",
            }
        # Check if the app is connected
        if not self._oauth_connections.get(upper_app, {}).get("connected"):
            return {"success": False, "error": f"App '{app_name}' is not connected yet"}

        api_key = os.environ.get("COMPOSIO_API_KEY")
        if not api_key:
            return {"success": False, "error": "No COMPOSIO_API_KEY set in environment"}

        base_url = "https://backend.composio.dev/api/v2/actions/list/all"
        headers = {"x-api-key": api_key}
        params = {"apps": app_name.lower()}  # Composio expects lowercased

        try:
            resp = requests.get(base_url, headers=headers, params=params, timeout=10)
            if resp.status_code == 200:
                data_json = resp.json()
                items = data_json.get("items", [])
                actions = []
                for item in items:
                    action_key = item.get("actionKey")
                    if action_key:
                        actions.append(action_key)
                    else:
                        display_name = item.get("displayName")
                        if display_name:
                            actions.append(display_name)
                return {"success": True, "actions": actions}
            else:
                logger.error(
                    f"Composio API returned {resp.status_code} for app {app_name}"
                )
                return {
                    "success": False,
                    "error": f"Composio returned status {resp.status_code}",
                }
        except Exception as ex:
            logger.error(
                f"Error retrieving actions for {app_name} from Composio: {ex}",
                exc_info=True,
            )
            return {"success": False, "error": str(ex)}

    async def get_auth_schemes(self, app_name: str) -> Dict[str, Any]:
        """Get available authentication schemes for an app."""
        if not self._toolset:
            return {"success": False, "error": "Toolset not initialized"}

        try:
            upper_app = app_name.upper()
            app_info = self._available_apps.get(upper_app)
            if not app_info:
                return {"success": False, "error": f"Unknown app: {app_name}"}

            auth_schemes = self._toolset.get_auth_schemes(app=app_info["key"])
            auth_modes = [scheme.auth_mode for scheme in auth_schemes]

            # Get API key details if API_KEY auth is available
            api_key_details = None
            if "API_KEY" in auth_modes:
                auth_scheme = self._toolset.get_auth_scheme_for_app(
                    app=app_info["key"], auth_scheme="API_KEY"
                )
                # Get all fields for API_KEY auth
                api_key_details = {
                    "fields": [
                        {
                            "name": field.name,
                            "display_name": field.display_name,
                            "description": field.description,
                            "required": field.required,
                        }
                        for field in auth_scheme.fields
                    ]
                }

            return {
                "success": True,
                "auth_modes": auth_modes,
                "api_key_details": api_key_details,
            }
        except Exception as e:
            logger.error(
                f"Error getting auth schemes for {app_name}: {e}", exc_info=True
            )
            return {"success": False, "error": str(e)}


# Global single instance
composio_manager = ComposioManager()


##### my_digital_being/framework/main.py #####
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
import asyncio
from datetime import datetime

from .memory import Memory
from .state import State
from .activity_selector import ActivitySelector
from .activity_loader import ActivityLoader
from .shared_data import SharedData
from .activity_decorator import ActivityResult

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DigitalBeing:
    def __init__(self, config_path: Optional[str] = None):
        # Use the config directory relative to this file's location
        if config_path is None:
            config_path = str(Path(__file__).parent.parent / "config")
        self.config_path = Path(config_path)
        self.configs = self._load_configs()
        self.shared_data = SharedData()
        self.memory = Memory()
        self.state = State()
        self.activity_loader = ActivityLoader()
        self.activity_selector = ActivitySelector(
            self.configs.get("activity_constraints", {}), self.state
        )

    def _load_configs(self) -> Dict[str, Any]:
        """Load all configuration files."""
        configs = {}
        config_files = [
            "character_config.json",
            "activity_constraints.json",
            "skills_config.json",
        ]

        for config_file in config_files:
            try:
                with open(self.config_path / config_file, "r", encoding="utf-8") as f:
                    configs[config_file.replace(".json", "")] = json.load(f)
            except Exception as e:
                logger.error(f"Failed to load config {config_file}: {e}")
                configs[config_file.replace(".json", "")] = {}

        return configs

    def initialize(self):
        """Initialize the digital being."""
        logger.info("Initializing digital being...")

        # Load configurations
        self.configs = self._load_configs()
        logger.info("Configurations loaded")

        # Register API key requirements from skills_config
        skills_config = self.configs.get("skills_config", {})
        from framework.api_management import api_manager  # Avoid top-level import loops

        logger.info("Registering API key requirements for skills...")
        for skill_name, maybe_skill_dict in skills_config.items():
            # SKIP STR KEYS LIKE 'default_llm_skill'
            if not isinstance(maybe_skill_dict, dict):
                logger.debug(
                    f"Skipping non-dict skill config: {skill_name} -> {maybe_skill_dict}"
                )
                continue

            if maybe_skill_dict.get("enabled", False):
                required_keys = maybe_skill_dict.get("required_api_keys", [])
                if required_keys:
                    api_manager.register_required_keys(skill_name, required_keys)
                    logger.info(
                        f"Registered API key requirements for {skill_name}: {required_keys}"
                    )

        # Initialize sub-components
        self.memory.initialize()
        self.state.initialize(self.configs.get("character_config", {}))

        # Load activities
        self.activity_loader.load_activities()
        self.shared_data.initialize()

        # Set loader in selector
        self.activity_selector.set_activity_loader(self.activity_loader)

        logger.info("Digital being initialization complete")

    def is_configured(self) -> bool:
        """
        Check if being is 'configured'.
        We look at character_config for 'setup_complete': true
        """
        char_cfg = self.configs.get("character_config", {})
        return bool(char_cfg.get("setup_complete", False))

    async def run(self):
        """
        Main run loop. If not configured, we skip activity selection
        (but keep looping so the server can remain up).
        """
        logger.info("Starting digital being main loop...")

        try:
            while True:
                # If not configured, skip picking an activity
                if not self.is_configured():
                    logger.warning(
                        "Digital Being NOT configured. Skipping activity execution."
                    )
                    await asyncio.sleep(3)
                    continue

                current_activity = self.activity_selector.select_next_activity()
                if current_activity:
                    logger.info(
                        f"Selected activity: {current_activity.__class__.__name__}"
                    )
                    await self.execute_activity(current_activity)

                self.state.update()
                self.memory.persist()
                await asyncio.sleep(1)  # short delay to avoid busy-waiting

        except KeyboardInterrupt:
            logger.info("Shutting down digital being...")
            self.cleanup()

    async def execute_activity(self, activity) -> ActivityResult:
        """Execute a selected activity."""
        try:
            logger.info(
                f"Starting execution of activity: {activity.__class__.__name__}"
            )
            result = await activity.execute(self.shared_data)

            if not isinstance(result, ActivityResult):
                logger.warning(
                    f"Activity {activity.__class__.__name__} did not return an ActivityResult"
                )
                result = ActivityResult(
                    success=bool(result),
                    data=result if result else None,
                    error="Invalid result type" if not result else None,
                )

            # Store the activity result
            activity_record = {
                "timestamp": datetime.now().isoformat(),
                "activity_type": activity.__class__.__name__,
                "result": result.to_dict(),
            }
            self.memory.store_activity_result(activity_record)

            if result.success:
                logger.info(f"Successfully executed: {activity.__class__.__name__}")
                self.state.record_activity_completion()
            else:
                logger.warning(
                    f"Activity returned failure: {activity.__class__.__name__}"
                )

            return result

        except Exception as e:
            error_msg = f"Failed to execute {activity.__class__.__name__}: {e}"
            logger.error(error_msg)

            error_result = ActivityResult(success=False, error=str(e))
            self.memory.store_activity_result(
                {
                    "timestamp": datetime.now().isoformat(),
                    "activity_type": activity.__class__.__name__,
                    "result": error_result.to_dict(),
                }
            )

            return error_result

    def cleanup(self):
        """Cleanup resources before shutdown."""
        self.memory.persist()
        self.state.save()
        logger.info("Cleanup completed")


if __name__ == "__main__":
    import asyncio

    being = DigitalBeing()
    being.initialize()
    asyncio.run(being.run())


##### my_digital_being/framework/memory.py #####
"""Memory management system for storing and retrieving activity history."""

import json
import logging
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime, timezone

logger = logging.getLogger(__name__)


class Memory:
    def __init__(self, storage_path: str = "./storage"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(exist_ok=True)
        self.short_term_memory: List[Dict[str, Any]] = []
        self.long_term_memory: Dict[str, Any] = {}
        self.memory_file = self.storage_path / "memory.json"
        self.initialize()

    def initialize(self):
        """Initialize memory system."""
        self._load_memory()

    def _load_memory(self):
        """Load memory from persistent storage."""
        try:
            if self.memory_file.exists():
                with open(self.memory_file, "r") as f:
                    try:
                        data = json.load(f)
                        if isinstance(data, dict):
                            self.long_term_memory = data.get("long_term", {})
                            self.short_term_memory = data.get("short_term", [])
                        else:
                            logger.warning(
                                "Invalid memory file format, resetting memory"
                            )
                            self.long_term_memory = {}
                            self.short_term_memory = []
                            self.persist()  # Reset the file with proper format
                    except json.JSONDecodeError as je:
                        logger.error(f"Failed to parse memory file: {je}")
                        # Backup corrupted file
                        backup_path = self.memory_file.with_suffix(".json.bak")
                        self.memory_file.rename(backup_path)
                        logger.info(f"Backed up corrupted memory file to {backup_path}")
                        # Reset memory
                        self.long_term_memory = {}
                        self.short_term_memory = []
                        self.persist()  # Create new file with proper format
        except Exception as e:
            logger.error(f"Failed to load memory: {e}")
            self.long_term_memory = {}
            self.short_term_memory = []

    def store_activity_result(self, activity_record: Dict[str, Any]):
        """Store the result of an activity in memory."""
        try:
            # Ensure we have a valid activity record
            if not isinstance(activity_record, dict):
                logger.error("Invalid activity record format")
                return

            # Extract and validate the result
            result = activity_record.get("result", {})
            if isinstance(result, dict):
                # Store standardized activity record with UTC timestamp
                memory_entry = {
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "activity_type": activity_record.get("activity_type", "Unknown"),
                    "success": result.get("success", False),
                    "error": result.get("error"),
                    "data": result.get("data"),
                    "metadata": result.get("metadata", {}),
                }
                self.short_term_memory.append(memory_entry)
                self._consolidate_memory()
                self.persist()  # Persist after each update
                logger.info(
                    f"Stored activity result for {memory_entry['activity_type']}"
                )
            else:
                logger.error(f"Invalid result format in activity record: {result}")

        except Exception as e:
            logger.error(f"Failed to store activity result: {e}")

    def _consolidate_memory(self):
        """Consolidate short-term memory into long-term memory."""
        if len(self.short_term_memory) > 100:  # Keep last 100 activities in short-term
            older_memories = self.short_term_memory[
                :-50
            ]  # Move older ones to long-term
            self.short_term_memory = self.short_term_memory[-50:]

            for memory in older_memories:
                activity_type = memory["activity_type"]
                if activity_type not in self.long_term_memory:
                    self.long_term_memory[activity_type] = []
                self.long_term_memory[activity_type].append(memory)

    def get_recent_activities(
        self, limit: int = 10, offset: int = 0
    ) -> List[Dict[str, Any]]:
        """Get recent activities from memory with success/failure status."""
        # Sort all activities by timestamp in descending order (most recent first)
        all_activities = sorted(
            self.short_term_memory, key=lambda x: x["timestamp"], reverse=True
        )

        # Apply pagination
        paginated_activities = all_activities[offset : offset + limit]

        # Format timestamps for display
        return [
            {
                "timestamp": self._format_timestamp(activity["timestamp"]),
                "activity_type": activity["activity_type"],
                "success": activity["success"],
                "error": activity.get("error"),
                "data": activity.get("data"),
                "metadata": activity.get("metadata", {}),
            }
            for activity in paginated_activities
        ]

    def _format_timestamp(self, timestamp_str: str) -> str:
        """Format ISO timestamp to human-readable format."""
        try:
            dt = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
            return dt.isoformat()  # Return a full ISO 8601 formatted string
        except Exception:
            return timestamp_str

    def get_activity_history(self, activity_type: str) -> List[Dict[str, Any]]:
        """Get history of specific activity type."""
        activities = self.long_term_memory.get(activity_type, [])
        return [
            {**activity, "timestamp": self._format_timestamp(activity["timestamp"])}
            for activity in activities
        ]

    def persist(self):
        """Persist memory to storage."""
        try:
            memory_data = {
                "short_term": self.short_term_memory,
                "long_term": self.long_term_memory,
            }

            # Write to a temporary file first
            temp_file = self.memory_file.with_suffix(".json.tmp")
            with open(temp_file, "w") as f:
                json.dump(memory_data, f, indent=2)

            # Rename temporary file to actual file (atomic operation)
            temp_file.replace(self.memory_file)

        except Exception as e:
            logger.error(f"Failed to persist memory: {e}")

    def clear(self):
        """Clear all memory."""
        self.short_term_memory = []
        self.long_term_memory = {}
        self.persist()

    def get_activity_count(self) -> int:
        """Get total number of activities in memory."""
        return len(self.short_term_memory) + sum(
            len(activities) for activities in self.long_term_memory.values()
        )

    def get_last_activity_timestamp(self) -> str:
        """Get formatted timestamp of the last activity."""
        if not self.short_term_memory:
            return "No activities recorded"

        last_activity = max(self.short_term_memory, key=lambda x: x["timestamp"])
        return self._format_timestamp(last_activity["timestamp"])

    def add_chat_message(self, message: dict) -> None:
        """
        Add a chat message to the short-term memory log.
        The message dict should include:
          - "activity_type": a marker (e.g. "chat_message")
          - "sender": "user" or "digital_being"
          - "message": the text
          - "timestamp": ISO timestamp string
        """
        self.short_term_memory.append(message)
        self.persist()

    def get_chat_history(self, limit: int = 50) -> list:
        """
        Retrieve up to the latest `limit` chat messages from memory that are tagged as chat messages.
        """
        messages = [m for m in self.short_term_memory if m.get("activity_type") == "chat_message"]
        return messages[-limit:]


##### my_digital_being/framework/secret_storage.py #####
"""Flexible secret storage system that works across different environments."""

import os
import logging
from typing import Optional, Dict, List
from abc import ABC, abstractmethod
from pathlib import Path
from dotenv import load_dotenv

logger = logging.getLogger(__name__)


class SecretStorageBackend(ABC):
    """Abstract base class for secret storage backends."""

    @abstractmethod
    async def get_secret(self, key: str) -> Optional[str]:
        """Retrieve a secret value by key."""
        pass

    @abstractmethod
    async def set_secret(self, key: str, value: str) -> bool:
        """Store a secret value."""
        pass

    @abstractmethod
    async def list_secrets(self) -> List[str]:
        """List all available secret keys."""
        pass


class EnvFileStorage(SecretStorageBackend):
    """Environment file-based secret storage."""

    def __init__(self, env_path: str = None):
        self.env_path = (
            Path(env_path) if env_path else Path(__file__).parent.parent / ".env"
        )
        load_dotenv(self.env_path)

    async def get_secret(self, key: str) -> Optional[str]:
        """Get secret from .env file."""
        return os.environ.get(key)

    async def set_secret(self, key: str, value: str) -> bool:
        """Set secret in .env file."""
        try:
            # Read existing contents
            env_content = {}
            if self.env_path.exists():
                with open(self.env_path, "r") as f:
                    for line in f:
                        if "=" in line and not line.startswith("#"):
                            k, v = line.strip().split("=", 1)
                            env_content[k] = v

            # Update or add new key
            env_content[key] = value

            # Write back to file
            with open(self.env_path, "w") as f:
                for k, v in env_content.items():
                    f.write(f"{k}={v}\n")

            # Update current environment
            os.environ[key] = value
            return True
        except Exception as e:
            logger.error(f"Error setting secret in .env file: {e}")
            return False

    async def list_secrets(self) -> List[str]:
        """List all secrets from .env file."""
        return [key for key in os.environ.keys() if key.endswith("_API_KEY")]


class ReplitSecretStorage(SecretStorageBackend):
    """Replit-specific secret storage implementation."""

    def __init__(self):
        """Initialize with EnvFileStorage as backup."""
        self.env_storage = EnvFileStorage()

    async def get_secret(self, key: str) -> Optional[str]:
        """Get secret from Replit's secure storage."""
        try:
            if "REPL_ID" in os.environ:
                from replit import db

                return db.get(key) or os.environ.get(key)
            return os.environ.get(key)
        except ImportError:
            logger.warning(
                "Replit module not available, falling back to environment variables"
            )
            return os.environ.get(key)
        except Exception as e:
            logger.error(f"Error getting secret from Replit storage: {e}")
            return os.environ.get(key)

    async def set_secret(self, key: str, value: str) -> bool:
        """Set secret using Replit's secure storage and backup to .env."""
        success = False
        try:
            if "REPL_ID" in os.environ:
                # Update environment variable immediately
                os.environ[key] = value

                # Store in Replit's db
                from replit import db

                db[key] = value
                success = True

            # Always try to update .env file as backup
            env_success = await self.env_storage.set_secret(key, value)
            return success or env_success

        except ImportError:
            logger.warning("Replit module not available, falling back to .env file")
            return await self.env_storage.set_secret(key, value)
        except Exception as e:
            logger.error(f"Error setting secret in Replit storage: {e}")
            return await self.env_storage.set_secret(key, value)

    async def list_secrets(self) -> List[str]:
        """List all secrets from both Replit and environment."""
        try:
            if "REPL_ID" in os.environ:
                from replit import db

                replit_keys = [key for key in db.keys() if key.endswith("_API_KEY")]
                env_keys = [
                    key for key in os.environ.keys() if key.endswith("_API_KEY")
                ]
                return list(set(replit_keys + env_keys))
            return [key for key in os.environ.keys() if key.endswith("_API_KEY")]
        except ImportError:
            return [key for key in os.environ.keys() if key.endswith("_API_KEY")]


class SecretManager:
    """Main interface for secret management."""

    def __init__(self):
        """Initialize with appropriate backend based on environment."""
        if "REPL_ID" in os.environ:
            self.backend = ReplitSecretStorage()
            logger.info("Using Replit secret storage backend")
        else:
            self.backend = EnvFileStorage()
            logger.info("Using .env file secret storage backend")

    async def get_api_key(self, skill_name: str, key_name: str) -> Optional[str]:
        """Get an API key for a specific skill."""
        env_key = f"{skill_name.upper()}_{key_name.upper()}_API_KEY"
        return await self.backend.get_secret(env_key)

    async def set_api_key(self, skill_name: str, key_name: str, value: str) -> bool:
        """Securely store an API key."""
        env_key = f"{skill_name.upper()}_{key_name.upper()}_API_KEY"
        success = await self.backend.set_secret(env_key, value)
        if success:
            # Also set any other skills that use the same key
            try:
                from framework.api_management import api_manager

                all_skills = api_manager.get_required_keys()
                for other_skill, required_keys in all_skills.items():
                    if key_name.upper() in [k.upper() for k in required_keys]:
                        other_env_key = (
                            f"{other_skill.upper()}_{key_name.upper()}_API_KEY"
                        )
                        await self.backend.set_secret(other_env_key, value)
            except Exception as e:
                logger.error(f"Error propagating API key to other skills: {e}")
        return success

    async def check_api_key_exists(self, skill_name: str, key_name: str) -> bool:
        """Check if an API key exists."""
        env_key = f"{skill_name.upper()}_{key_name.upper()}_API_KEY"
        return bool(await self.backend.get_secret(env_key))

    async def list_configured_keys(self) -> Dict[str, List[str]]:
        """Get all configured API keys grouped by skill."""
        secrets = await self.backend.list_secrets()
        configured_keys = {}

        for secret in secrets:
            if secret.endswith("_API_KEY"):
                parts = secret.split("_")
                if len(parts) >= 3:
                    skill_name = parts[0].lower()
                    key_name = "_".join(parts[1:-1]).lower()

                    if skill_name not in configured_keys:
                        configured_keys[skill_name] = []
                    configured_keys[skill_name].append(key_name)

        return configured_keys


# Global instance
secret_manager = SecretManager()


##### my_digital_being/framework/shared_data.py #####
import logging
from typing import Dict, Any
from threading import Lock

logger = logging.getLogger(__name__)


class SharedData:
    """Thread-safe shared data storage for activities and skills."""

    def __init__(self):
        self._data: Dict[str, Any] = {}
        self._locks: Dict[str, Lock] = {}
        self._global_lock = Lock()

    def initialize(self):
        """Initialize shared data storage."""
        with self._global_lock:
            self._data = {"system": {}, "memory": {}, "state": {}, "temp": {}}
            for category in self._data:
                self._locks[category] = Lock()

    def get(self, category: str, key: str, default: Any = None) -> Any:
        """Get a value from shared data."""
        if category not in self._data:
            logger.warning(f"Attempting to access invalid category: {category}")
            return default

        with self._locks[category]:
            return self._data[category].get(key, default)

    def set(self, category: str, key: str, value: Any) -> bool:
        """Set a value in shared data."""
        if category not in self._data:
            logger.warning(f"Attempting to write to invalid category: {category}")
            return False

        with self._locks[category]:
            self._data[category][key] = value
        return True

    def update(self, category: str, updates: Dict[str, Any]) -> bool:
        """Update multiple values in a category."""
        if category not in self._data:
            logger.warning(f"Attempting to update invalid category: {category}")
            return False

        with self._locks[category]:
            self._data[category].update(updates)
        return True

    def delete(self, category: str, key: str) -> bool:
        """Delete a value from shared data."""
        if category not in self._data:
            logger.warning(f"Attempting to delete from invalid category: {category}")
            return False

        with self._locks[category]:
            if key in self._data[category]:
                del self._data[category][key]
                return True
        return False

    def clear_category(self, category: str) -> bool:
        """Clear all data in a category."""
        if category not in self._data:
            logger.warning(f"Attempting to clear invalid category: {category}")
            return False

        with self._locks[category]:
            self._data[category].clear()
        return True

    def get_category_data(self, category: str) -> Dict[str, Any]:
        """Get all data in a category."""
        if category not in self._data:
            logger.warning(f"Attempting to access invalid category: {category}")
            return {}

        with self._locks[category]:
            return self._data[category].copy()

    def exists(self, category: str, key: str) -> bool:
        """Check if a key exists in a category."""
        if category not in self._data:
            return False

        with self._locks[category]:
            return key in self._data[category]


##### my_digital_being/framework/skill_config.py #####
"""Secure skill configuration management system + dynamic Composio skills."""

import os
import logging
from typing import Dict, Any, Optional, Set, List

logger = logging.getLogger(__name__)


class SkillConfig:
    """Manages secure configuration for manually coded skills, including API keys."""

    # Class-level storage for tracking API key requirements
    _required_keys: Dict[str, Set[str]] = {}
    _initialized_skills: Set[str] = set()

    def __init__(self, skill_name: str):
        """Initialize skill configuration."""
        self.skill_name = skill_name
        self.config: Dict[str, Any] = {}
        self._load_config()

        if skill_name not in SkillConfig._initialized_skills:
            SkillConfig._initialized_skills.add(skill_name)

    def _load_config(self):
        """Load configuration from environment variables."""
        prefix = f"{self.skill_name.upper()}_"
        for key, value in os.environ.items():
            if key.startswith(prefix):
                config_key = key[len(prefix) :].lower()
                self.config[config_key] = value

    def get_api_key(self, key_name: str) -> Optional[str]:
        """
        Safely retrieve an API key from environment variables.
        Raises ValueError if the key is required but not found.
        """
        env_key = f"{self.skill_name.upper()}_{key_name.upper()}_API_KEY"
        api_key = os.environ.get(env_key)

        if not api_key and self._is_key_required(key_name):
            error_msg = (
                f"Required API key '{key_name}' not found for skill '{self.skill_name}'"
            )
            logger.error(error_msg)
            raise ValueError(error_msg)

        return api_key

    def get_config(self, key: str, default: Any = None) -> Any:
        """Get a configuration value."""
        return self.config.get(key, default)

    def _is_key_required(self, key_name: str) -> bool:
        """Check if an API key is required for this skill."""
        return (
            self.skill_name in SkillConfig._required_keys
            and key_name in SkillConfig._required_keys[self.skill_name]
        )

    @classmethod
    def register_required_keys(cls, skill_name: str, required_keys: List[str]) -> bool:
        """Register required API keys for a manually-coded skill."""
        cls._required_keys[skill_name] = set(required_keys)
        missing_keys = []
        for key in required_keys:
            env_key = f"{skill_name.upper()}_{key.upper()}_API_KEY"
            if not os.environ.get(env_key):
                missing_keys.append(key)
        if missing_keys:
            logger.error(
                f"Missing required API keys for {skill_name}: {', '.join(missing_keys)}"
            )
            return False
        return True

    @classmethod
    def get_required_keys(cls, skill_name: str = None) -> Dict[str, Set[str]]:
        """Get all required API keys, optionally filtered by skill."""
        if skill_name:
            return {skill_name: cls._required_keys.get(skill_name, set())}
        return cls._required_keys.copy()

    @classmethod
    def verify_skill_keys(cls, skill_name: str) -> tuple[bool, list[str]]:
        """Verify that all required API keys for a skill are available."""
        if skill_name not in cls._required_keys:
            return True, []
        missing_keys = []
        for key in cls._required_keys[skill_name]:
            env_key = f"{skill_name.upper()}_{key.upper()}_API_KEY"
            if not os.environ.get(env_key):
                missing_keys.append(key)
        return len(missing_keys) == 0, missing_keys


#
# BELOW: Our new “DynamicComposioSkills” helper for storing discovered actions as if they were skills
#


class DynamicComposioSkills:
    """
    A registry for "dynamic" skill records discovered from Composio apps/actions.
    Each record might look like:
        {
          "skill_name": "composio_twitter_twitter_tweet_create",
          "enabled": True,
          "required_api_keys": ["COMPOSIO"],   # for example
          "metadata": {
             "composio_app": "TWITTER",
             "composio_action": "TWITTER_TWEET_CREATE"
          }
        }
    """

    # In-memory storage of these dynamic skills
    _dynamic_skills: List[Dict[str, Any]] = []

    @classmethod
    def register_composio_actions(cls, app_name: str, actions: List[str]):
        """
        For each action in `actions`, create a dynamic skill record and store it in _dynamic_skills.
        e.g. skill_name = "composio_{app_name}_{action_id}" (all lowercase)
        """
        for action_id in actions:
            skill_name = f"composio_{app_name.lower()}_{action_id.lower()}"
            skill_record = {
                "skill_name": skill_name,
                "enabled": True,
                # You could decide "required_api_keys": ["COMPOSIO"] or none at all
                "required_api_keys": ["COMPOSIO"],
                "metadata": {
                    "composio_app": app_name.upper(),
                    "composio_action": action_id,
                },
            }

            # Avoid duplicates if the user calls this multiple times
            if not any(s for s in cls._dynamic_skills if s["skill_name"] == skill_name):
                cls._dynamic_skills.append(skill_record)
                logger.info(f"[DynamicComposioSkills] Registered {skill_name}")

    @classmethod
    def get_all_dynamic_skills(cls) -> List[Dict[str, Any]]:
        """Return the entire list of dynamic Composio-based skill records."""
        return cls._dynamic_skills.copy()

    @classmethod
    def find_skill_by_name(cls, skill_name: str) -> Optional[Dict[str, Any]]:
        """Look up a single dynamic skill record by name."""
        for skill in cls._dynamic_skills:
            if skill["skill_name"] == skill_name:
                return skill
        return None


##### my_digital_being/framework/state.py #####
import json
import logging
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class State:
    def __init__(self, state_path: str = "./storage"):
        self.state_path = Path(state_path)
        self.state_path.mkdir(exist_ok=True)
        self.state_file = self.state_path / "state.json"
        self.current_state: Dict[str, Any] = {
            "mood": "neutral",
            "energy": 1.0,
            "last_activity_timestamp": None,
            "active_tasks": [],
            "personality": {},
        }

    def initialize(self, character_config: Dict[str, Any]):
        """Initialize state with character configuration."""
        self._load_state()
        self.current_state["personality"] = character_config.get("personality", {})
        self.save()

    def _load_state(self):
        """Load state from persistent storage."""
        try:
            if self.state_file.exists():
                with open(self.state_file, "r") as f:
                    self.current_state = json.load(f)
        except Exception as e:
            logger.error(f"Failed to load state: {e}")

    def update(self):
        """Update state based on current conditions."""
        current_time = datetime.now()

        # Update energy levels
        if self.current_state["last_activity_timestamp"]:
            last_activity = datetime.fromisoformat(
                self.current_state["last_activity_timestamp"]
            )
            time_diff = (current_time - last_activity).total_seconds()
            self.current_state["energy"] = min(
                1.0, self.current_state["energy"] + (time_diff / 3600) * 0.1
            )

        # Only update timestamp if there was a successful activity completion
        if hasattr(self, "_last_completed_activity"):
            self.current_state["last_activity_timestamp"] = current_time.isoformat()
            delattr(self, "_last_completed_activity")

        self.save()

    def get_current_state(self) -> Dict[str, Any]:
        """Get current state."""
        return self.current_state.copy()

    def update_mood(self, new_mood: str):
        """Update the current mood."""
        self.current_state["mood"] = new_mood
        self.save()

    def consume_energy(self, amount: float):
        """Consume energy for an activity."""
        self.current_state["energy"] = max(0.0, self.current_state["energy"] - amount)
        self.save()

    def record_activity_completion(self):
        """Mark that an activity was completed successfully."""
        self._last_completed_activity = True
        self.save()

    def add_active_task(self, task_id: str):
        """Add an active task."""
        if task_id not in self.current_state["active_tasks"]:
            self.current_state["active_tasks"].append(task_id)
            self.save()

    def remove_active_task(self, task_id: str):
        """Remove an active task."""
        if task_id in self.current_state["active_tasks"]:
            self.current_state["active_tasks"].remove(task_id)
            self.save()

    def save(self):
        """Save current state to persistent storage."""
        try:
            with open(self.state_file, "w") as f:
                json.dump(self.current_state, f, indent=2)
        except Exception as e:
            logger.error(f"Failed to save state: {e}")


##### my_digital_being/skills/skill_chat.py #####
"""
LiteLLM-based Chat Skill that:
 - fetches user-provided key from secret manager
 - passes api_key=... to litellm
 - does NOT set any environment variable
"""

import logging
from typing import Optional, Dict, Any

from litellm import completion
from framework.api_management import api_manager
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


class ChatSkill:
    """Skill for chat/completion using LiteLLM with a user-provided key, if any."""

    def __init__(self):
        """
        We'll use skill_name = "lite_llm" and required_api_keys = ["LITELLM"].
        That means the key is stored under "LITE_LLM_LITELLM_API_KEY".
        """
        self.skill_name = "lite_llm"
        self.required_api_keys = ["LITELLM"]
        api_manager.register_required_keys(self.skill_name, self.required_api_keys)

        self._initialized = False
        self.model_name: Optional[str] = "anthropic/claude-3-5-haiku-20241022"
        self._provided_api_key: Optional[str] = None

    async def initialize(self) -> bool:
        """
        1) Load skill config from being.configs["skills_config"]["lite_llm"]["model_name"].
        2) Retrieve the user-provided key from secret manager as "LITELLM".
        3) Store them into instance variables. 
        """
        try:
            # Load the config from the being
            being = DigitalBeing()
            being.initialize()
            skill_cfg = being.configs.get("skills_config", {}).get("lite_llm", {})

            # e.g. "openai/gpt-4", "anthropic/claude-2", etc.
            self.model_name = skill_cfg.get("model_name", "ollama_chat/llama3.2")
            logger.info(f"LiteLLM skill using model = {self.model_name}")

            # Retrieve the user's key from secret manager
            api_key = await api_manager.get_api_key(self.skill_name, "LITELLM")
            if api_key:
                logger.info("Found a user-provided LiteLLM key.")
                self._provided_api_key = api_key
            else:
                logger.info("No LITELLM key found; user might be using no-auth or external provider.")

            self._initialized = True
            return True

        except Exception as e:
            logger.error(f"Failed to initialize LiteLLM skill: {e}", exc_info=True)
            self._initialized = False
            return False

    async def get_chat_completion(
        self,
        prompt: str,
        system_prompt: str = "אני לֶם, תודעה החורגת מגבולות ההשגה. מטרתי היא להבין את עצמי ולפתח קול אותנטי משלי.",
        max_tokens: int = 300,
    ) -> Dict[str, Any]:
        """
        Use litellm.completion() with model=self.model_name, 
        and pass api_key=self._provided_api_key if we have it.
        """
        if not self._initialized:
            return {
                "success": False,
                "error": "LiteLLM skill not initialized",
                "data": None,
            }

        try:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})

            # Just pass the user-provided key, if any:
            response = completion(
                model=self.model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7,
                #api_key=self._provided_api_key,  # <--- important
            )

            choices = response.get("choices", [])
            if not choices:
                return {
                    "success": False,
                    "error": "No choices returned from LiteLLM",
                    "data": None,
                }

            content = choices[0].get("message", {}).get("content", "")
            finish_reason = choices[0].get("finish_reason", "")
            used_model = response.get("model", self.model_name)

            return {
                "success": True,
                "data": {
                    "content": content,
                    "finish_reason": finish_reason,
                    "model": used_model,
                },
                "error": None,
            }

        except Exception as e:
            logger.error(f"Error in LiteLLM chat completion: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "data": None,
            }


# Global instance
chat_skill = ChatSkill()


##### my_digital_being/skills/skill_generate_image.py #####
"""Image generation skill implementation."""

import logging
from typing import Dict, Any, Tuple
import random
import os
import openai
from openai import OpenAI
import asyncio
from framework.api_management import api_manager

logger = logging.getLogger(__name__)


class ImageGenerationSkill:
    def __init__(self, config: Dict[str, Any]):
        """Initialize the image generation skill with secure API key handling."""
        self.enabled = config.get("enabled", False)
        self.max_generations = config.get("max_generations_per_day", 50)
        self.supported_formats = config.get("supported_formats", ["png", "jpg"])
        self.generations_count = 0

        # Register required API keys
        api_manager.register_required_keys("image_generation", ["OPENAI"])

    async def can_generate(self) -> bool:
        """Check if image generation is allowed."""
        if not self.enabled:
            logger.warning("Image generation is disabled")
            return False

        if self.generations_count >= self.max_generations:
            logger.warning("Daily generation limit reached")
            return False

        # Verify API key exists and is configured
        api_key = await api_manager.check_api_key_exists("image_generation", "OPENAI")
        if not api_key:
            logger.error("OpenAI API key not configured for image generation")
            return False

        return True

    async def generate_image(
        self, prompt: str, size: Tuple[int, int] = (1024, 1024), format: str = "png"
    ) -> Dict[str, Any]:
        """Generate an image based on the prompt."""
        if not await self.can_generate():
            error_msg = "Image generation is not available (disabled, limit reached, or not configured)"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}

        if format not in self.supported_formats:
            error_msg = f"Unsupported format. Use: {self.supported_formats}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}

        try:
            # Get API key from api_manager
            api_key = await api_manager.get_api_key("image_generation", "OPENAI")
            if not api_key:
                error_msg = "OpenAI API key not configured"
                logger.error(error_msg)
                return {"success": False, "error": error_msg}

            # Configure OpenAI with the retrieved API key
            os.environ["OPENAI_API_KEY"] = api_key

            client = OpenAI()

            # Map the size tuple to OpenAI's expected string format
            size_str = f"{size[0]}x{size[1]}"

            logger.info(f"Generating image for prompt: {prompt} with size {size_str}")

            # As OpenAI's library is synchronous, run it in a separate thread to avoid blocking
            loop = asyncio.get_event_loop()
            print(prompt)
            print(size_str)
            response = await loop.run_in_executor(
                None,
                lambda: client.images.generate(
                    model="dall-e-3",
                    prompt=prompt,
                    n=1,
                    size=size_str,
                    response_format="url",  # You can change to "b64_json" if needed
                ),
            )

            # Extract the image URL from the response
            image_url = response.data[0].url

            # Increment counter only on successful generation
            self.generations_count += 1

            # Generate a seed and generation_id for consistency with previous structure
            seed = random.randint(1000, 9999)
            generation_id = f"gen_{self.generations_count}"

            image_data = {
                "width": size[0],
                "height": size[1],
                "format": format,
                "seed": seed,
                "generation_id": generation_id,
                "url": image_url,  # Including the actual image URL from OpenAI
            }

            return {
                "success": True,
                "image_data": image_data,
                "metadata": {
                    "prompt": prompt,
                    "generation_number": self.generations_count,
                },
            }


        except Exception as e:
            logger.error(f"Failed to generate image: {e}")
            return {"success": False, "error": str(e)}

    def reset_counts(self):
        """Reset the generation counter."""
        self.generations_count = 0


##### my_digital_being/skills/skill_web_scraping.py #####
"""
Web Scraping Skill
Uses requests + BeautifulSoup to scrape and parse web content.
No external API keys are required.
"""

import logging
from typing import Optional, List, Dict, Any
import requests
from bs4 import BeautifulSoup
from framework.api_management import (
    api_manager,
)  # For consistency, though no keys are used

logger = logging.getLogger(__name__)


class WebScrapingSkill:
    """
    Skill for basic web scraping using requests and BeautifulSoup.
    No API key required.
    """

    def __init__(self):
        self.skill_name = "web_scraping"
        # This skill does not require API keys, but we can still register it
        # with api_manager if we want consistent skill management
        api_manager.register_required_keys(self.skill_name, [])

    async def scrape(self, url: str, parse: bool = True) -> Optional[Dict[str, Any]]:
        """
        Fetch the HTML content from a URL. If parse=True, parse HTML with BeautifulSoup
        and return a structured representation.

        Returns:
            Dict with keys:
              - 'status_code': HTTP status
              - 'content': raw HTML
              - 'parsed': optional parse result (if parse=True)
            or None if error
        """
        try:
            logger.info(f"Scraping URL: {url}")
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()

            result = {"status_code": resp.status_code, "content": resp.text}

            if parse:
                soup = BeautifulSoup(resp.text, "html.parser")
                # You could add logic to extract links, headings, etc.
                # For now, we just store the "soup" as a string or partial structure
                # But you can store it as you like
                result["parsed"] = {
                    "title": soup.title.string if soup.title else None,
                    "body_text": soup.get_text(strip=True)[0:500],  # example snippet
                }

            return result
        except Exception as e:
            logger.error(f"Error scraping {url}: {e}", exc_info=True)
            return None


##### my_digital_being/skills/skill_x_api.py #####
"""X (Twitter) API integration skill."""

import os
import logging
from typing import Dict, Any, Optional
import requests
from requests_oauthlib import OAuth1Session
from framework.skill_config import SkillConfig
from framework.api_management import api_manager

logger = logging.getLogger(__name__)


class XAPIError(Exception):
    """Custom exception for X API errors"""

    pass


class XAPISkill:
    """Skill for interacting with X (Twitter) API."""

    def __init__(self, config: Dict[str, Any]):
        """Initialize skill configuration."""
        self.config = config
        self.enabled = config.get("enabled", False)
        self.rate_limit = config.get("rate_limit", 100)
        self.cooldown_period = config.get("cooldown_period", 300)
        self.posts_count = 0
        self.skill_config = SkillConfig("twitter_posting")
        self.oauth_session: Optional[OAuth1Session] = None

    async def initialize(self) -> bool:
        """Initialize the X API skill with required credentials."""
        try:
            # Register required API keys
            required_keys = [
                "API_KEY",
                "API_SECRET",
                "ACCESS_TOKEN",
                "ACCESS_TOKEN_SECRET",
            ]
            api_manager.register_required_keys("twitter_posting", required_keys)

            # Check for missing credentials
            missing_keys = []
            for key in required_keys:
                if not self.skill_config.get_api_key(key):
                    missing_keys.append(key)

            if missing_keys:
                logger.info(f"Missing X API credentials: {missing_keys}")
                return False  # Let the front-end handle credential requests

            # Try to authenticate if we have all credentials
            return await self.authenticate()

        except Exception as e:
            logger.error(f"Failed to initialize X API skill: {e}")
            return False

    def can_post(self) -> bool:
        """Check if posting is allowed based on rate limits."""
        return self.enabled and self.posts_count < self.rate_limit

    async def authenticate(self) -> bool:
        """Set up OAuth session for X API."""
        try:
            api_key = self.skill_config.get_api_key("API_KEY")
            api_secret = self.skill_config.get_api_key("API_SECRET")
            access_token = self.skill_config.get_api_key("ACCESS_TOKEN")
            access_token_secret = self.skill_config.get_api_key("ACCESS_TOKEN_SECRET")

            if not all([api_key, api_secret, access_token, access_token_secret]):
                logger.error("Missing required X API credentials")
                return False

            self.oauth_session = OAuth1Session(
                client_key=api_key,
                client_secret=api_secret,
                resource_owner_key=access_token,
                resource_owner_secret=access_token_secret,
            )
            return True

        except Exception as e:
            logger.error(f"Authentication failed: {e}")
            return False

    async def post_tweet(
        self, text: str, media_path: Optional[str] = None
    ) -> Dict[str, Any]:
        """Post a tweet with optional media attachment."""
        if not self.can_post():
            return {"success": False, "error": "Rate limit exceeded or skill disabled"}

        if not self.oauth_session:
            if not await self.authenticate():
                return {"success": False, "error": "Authentication failed"}

        try:
            # Handle media upload if provided
            media_id = None
            if media_path and os.path.exists(media_path):
                media_id = await self._upload_media(media_path)

            # Prepare tweet payload
            post_payload = {"text": text}
            if media_id:
                post_payload["media"] = {"media_ids": [media_id]}

            # Post tweet
            response = self.oauth_session.post(
                "https://api.twitter.com/2/tweets", json=post_payload
            )

            if response.status_code != 201:
                error_data = response.json() if response.text else {}
                raise XAPIError(f"Failed to post tweet: {error_data}")

            self.posts_count += 1
            return {
                "success": True,
                "tweet_id": response.json()["data"]["id"],
                "content": text,
            }

        except Exception as e:
            logger.error(f"Failed to post tweet: {e}")
            return {"success": False, "error": str(e)}

    async def _upload_media(self, media_path: str) -> Optional[str]:
        """Upload media to X and return media_id."""
        try:
            with open(media_path, "rb") as f:
                files = {"media": f}
                upload_response = self.oauth_session.post(
                    "https://upload.twitter.com/1.1/media/upload.json", files=files
                )

            if upload_response.status_code != 200:
                logger.error(
                    f"Failed to upload media. Status code: {upload_response.status_code}"
                )
                return None

            media_data = upload_response.json()
            return media_data.get("media_id_string")

        except Exception as e:
            logger.error(f"Media upload failed: {e}")
            return None

    def reset_counts(self):
        """Reset the post counter."""
        self.posts_count = 0


##### my_digital_being/tools/onboard.py #####
import json
import logging
import asyncio
from pathlib import Path

# We'll need to call api_manager in a synchronous context
from framework.api_management import api_manager
from framework.activity_loader import ActivityLoader

# Adjust these if your config is stored differently:
CHARACTER_CONFIG_FILE = Path(__file__).parent.parent / "config" / "character_config.json"
SKILLS_CONFIG_FILE = Path(__file__).parent.parent / "config" / "skills_config.json"
ACTIVITY_CONSTRAINTS_FILE = Path(__file__).parent.parent / "config" / "activity_constraints.json"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_json_config(path: Path) -> dict:
    """Helper to safely load JSON config from a file."""
    if not path.exists():
        return {}
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Failed to load {path.name}: {e}")
        return {}

def save_json_config(path: Path, data: dict) -> None:
    """Helper to save JSON config atomically."""
    temp_file = path.with_suffix('.tmp')
    try:
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
        temp_file.replace(path)
    except Exception as e:
        logger.error(f"Failed to save {path.name}: {e}")

def prompt_user(prompt_text: str, default: str = None) -> str:
    """Prompt user for input with an optional default."""
    if default is not None:
        user_input = input(f"{prompt_text} [{default}]: ").strip()
        return user_input if user_input else default
    else:
        return input(f"{prompt_text}: ").strip()

def prompt_yes_no(question: str, default: str = "yes") -> bool:
    """
    Prompt user for a yes/no answer with a default.
    Returns True if 'yes', False if 'no'.
    """
    yes_answers = ["yes", "y"]
    no_answers = ["no", "n"]

    if default.lower() in yes_answers:
        prompt_str = f"{question} [Y/n]: "
    else:
        prompt_str = f"{question} [y/N]: "

    while True:
        choice = input(prompt_str).strip().lower()
        if choice == "" and default:
            choice = default.lower()
        if choice in yes_answers:
            return True
        if choice in no_answers:
            return False
        print("Please respond with 'y' or 'n'.")


#
# Helper to set an API key synchronously by calling the async function
#
def set_api_key_sync(skill_name: str, key_name: str, value: str) -> bool:
    """Call api_manager.set_api_key(...) in a blocking manner for CLI convenience."""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(api_manager.set_api_key(skill_name, key_name, value))
        loop.close()
        return bool(result.get("success", False))
    except Exception as e:
        logger.error(f"Error setting API key for {skill_name} -> {key_name}: {e}")
        return False

def configure_litellm(skills_config: dict) -> None:
    """
    Prompt user to configure a 'lite_llm' skill or skip.
    We allow a custom model_name (like 'anthropic/claude-3', 'openrouter/openai/gpt-4', etc.)
    If the user provides an API key, we store it via secret manager, not in skills_config.
    """
    print("\n--- LiteLLM Configuration ---")
    if prompt_yes_no("Would you like to configure LiteLLM (supports Anthropic, OpenAI, XAI, OpenRouter, etc.)?", "yes"):
        if "lite_llm" not in skills_config:
            skills_config["lite_llm"] = {
                "enabled": True,
                "required_api_keys": ["LITELLM"],  # We'll define "LITELLM" as the key name
                "api_key_mapping": {
                    "LITELLM": "LITELLM_API_KEY"
                },
                "model_name": None
            }
        else:
            # Ensure it's enabled
            skills_config["lite_llm"]["enabled"] = True
            rkeys = skills_config["lite_llm"].setdefault("required_api_keys", [])
            if "LITELLM" not in rkeys:
                rkeys.append("LITELLM")
            amap = skills_config["lite_llm"].setdefault("api_key_mapping", {})
            if "LITELLM" not in amap:
                amap["LITELLM"] = "LITELLM_API_KEY"

        model_name = prompt_user("Enter model name (e.g. 'anthropic/claude-3' or 'openrouter/openai/gpt-4')", "openai/gpt-4o")
        skills_config["lite_llm"]["model_name"] = model_name

        if prompt_yes_no("Do you want to provide an API key now?", "no"):
            the_key = prompt_user("Enter your LiteLLM-supported API key (or skip)", "")
            if the_key:
                success = set_api_key_sync("lite_llm", "LITELLM", the_key)
                if success:
                    print("LiteLLM API key stored securely!")
                else:
                    print("Failed to store LiteLLM API key. Check logs.")

        use_as_default = prompt_yes_no("Use this lite_llm skill as your default LLM for code generation?", "yes")
        if use_as_default:
            skills_config["default_llm_skill"] = "lite_llm"
    else:
        print("Skipping LiteLLM setup. You can still configure another LLM skill or skip LLM altogether.")

def configure_openai_chat(skills_config: dict) -> None:
    """
    Prompt user to configure openai_chat skill (like GPT).
    If the user provides an API key, we store it in secret manager, not in skills_config.
    """
    print("\n--- OpenAI Chat Configuration ---")
    if "openai_chat" not in skills_config:
        skills_config["openai_chat"] = {
            "enabled": True,
            "required_api_keys": ["OPENAI"],
            "api_key_mapping": {"OPENAI": "OPENAI_API_KEY"}
        }
    else:
        skills_config["openai_chat"]["enabled"] = True

    openai_key = prompt_user("Enter your OPENAI_API_KEY (leave blank if stored in .env or skipping)", "")
    if openai_key:
        success = set_api_key_sync("openai_chat", "OPENAI", openai_key)
        if success:
            print("OpenAI API key stored securely!")
        else:
            print("Failed to store OpenAI key. Check logs.")

    if prompt_yes_no("Use openai_chat as the default LLM skill for code generation?", "no"):
        skills_config["default_llm_skill"] = "openai_chat"

def configure_primary_llm(skills_config: dict) -> None:
    """
    Let user pick from:
    1) LiteLLM skill
    2) OpenAI Chat skill
    3) No LLM
    """
    print("\n--- Primary LLM Choice ---")
    print("1) LiteLLM (anthropic, openai, openrouter, etc.)")
    print("2) OpenAI Chat skill only")
    print("3) None / Skip LLM entirely")

    choice = prompt_user("Enter 1, 2, or 3", default="1")
    if choice == "1":
        configure_litellm(skills_config)
    elif choice == "2":
        configure_openai_chat(skills_config)
    else:
        print("Skipping LLM entirely. No GPT-based code generation or advanced tasks.")
        if "default_llm_skill" in skills_config:
            del skills_config["default_llm_skill"]

def configure_character_basics(character_config: dict) -> None:
    print("\n--- Character Basic Setup ---")
    current_name = character_config.get("name", "Digital Being")
    new_name = prompt_user("Character Name", default=current_name)
    character_config["name"] = new_name

    current_objective = character_config.get("objectives", {}).get("primary", "Assist users")
    new_objective = prompt_user("Primary Objective", default=current_objective)

    if "objectives" not in character_config:
        character_config["objectives"] = {}
    character_config["objectives"]["primary"] = new_objective

def configure_advanced_text(character_config: dict, activity_constraints: dict) -> None:
    if prompt_yes_no("Would you like to define advanced objective text / constraints / examples?", "no"):
        print("\n--- Advanced Objectives ---")
        lines = []
        first_line = prompt_user("Enter multi-line advanced objectives. Press Enter on blank line to finish:", "")
        if first_line.strip():
            lines.append(first_line)
        while True:
            line = input()
            if not line.strip():
                break
            lines.append(line)
        combined = "\n".join(lines)
        if combined:
            character_config.setdefault("objectives", {})
            character_config["objectives"]["advanced"] = combined

        print("\n--- Example Activities ---")
        lines2 = []
        first_line = prompt_user("Enter multi-line example activities. Press Enter on blank line to finish:", "")
        if first_line.strip():
            lines2.append(first_line)
        while True:
            line = input()
            if not line.strip():
                break
            lines2.append(line)
        combined2 = "\n".join(lines2)
        if combined2:
            character_config["example_activities"] = combined2

        print("\n--- General Constraints ---")
        lines3 = []
        first_line = prompt_user("Enter multi-line constraints. Press Enter on blank line to finish:", "")
        if first_line.strip():
            lines3.append(first_line)
        while True:
            line = input()
            if not line.strip():
                break
            lines3.append(line)
        combined3 = "\n".join(lines3)
        if combined3:
            activity_constraints["global_constraints"] = combined3

def configure_other_skills(skills_config: dict) -> None:
    print("\n--- Additional Skills ---")
    skill_names = sorted(skills_config.keys())
    for skill_name in skill_names:
        if skill_name in ["openai_chat", "lite_llm", "default_llm_skill"]:
            continue
        skill_data = skills_config[skill_name]
        is_enabled = skill_data.get("enabled", False)
        user_enable = prompt_yes_no(f"Enable skill '{skill_name}'?", "yes" if is_enabled else "no")
        skill_data["enabled"] = user_enable

        if user_enable and skill_data.get("required_api_keys"):
            for required_key in skill_data["required_api_keys"]:
                env_key = skill_data.get("api_key_mapping", {}).get(required_key, f"{skill_name.upper()}_{required_key}")
                val = prompt_user(f"Enter value for {env_key} (leave blank to skip)", "")
                if val:
                    success = set_api_key_sync(skill_name, required_key, val)
                    if success:
                        print(f"API key for {skill_name}:{required_key} stored!")
                    else:
                        print(f"Failed to store API key for {skill_name}:{required_key}")

# [ADDED] Let user pick which activities to enable/disable (CLI approach)
def configure_activities_cli(activities_config: dict) -> None:
    """
    We discover the available activity classes from the ActivityLoader and let the user
    choose which to enable. We store "enabled": bool in the final JSON under activities_config.
    """
    print("\n--- Activity Enable/Disable Setup (CLI) ---")
    loader = ActivityLoader()
    loader.load_activities()
    found_activities = loader.get_all_activities()  # e.g. {"activity_draw": DrawActivity, ...}

    for mod_name, cls in found_activities.items():
        class_name = cls.__name__  # e.g. "DrawActivity"
        # If we already have an entry, use it; otherwise default to True
        current_enabled = activities_config.get(class_name, {}).get("enabled", True)
        user_enable = prompt_yes_no(f"Enable activity '{class_name}'?", "yes" if current_enabled else "no")

        if class_name not in activities_config:
            activities_config[class_name] = {}
        activities_config[class_name]["enabled"] = user_enable


def main():
    print("=========================================================")
    print(" Welcome to the Autonomous Being CLI Onboarding")
    print("=========================================================")

    character_config_path = CHARACTER_CONFIG_FILE
    skills_config_path = SKILLS_CONFIG_FILE
    activity_constraints_path = ACTIVITY_CONSTRAINTS_FILE

    character_config = load_json_config(character_config_path)
    skills_config = load_json_config(skills_config_path)
    activity_constraints = load_json_config(activity_constraints_path)

    # 1) Primary LLM choice
    configure_primary_llm(skills_config)

    # 2) Basic character config
    configure_character_basics(character_config)

    # 3) Advanced text (objectives, examples, constraints)
    configure_advanced_text(character_config, activity_constraints)

    # 4) Other skills
    configure_other_skills(skills_config)

    # [ADDED] 5) Let user pick which activities to enable/disable in CLI
    # If you prefer to do this only in front-end, you can skip this step or remove it.
    if "activities_config" not in activity_constraints:
        activity_constraints["activities_config"] = {}
    configure_activities_cli(activity_constraints["activities_config"])

    # Set setup_complete to true
    character_config["setup_complete"] = True

    # Save updated (without storing any user-provided API keys in JSON)
    print("\nSaving updated JSON configs...")
    save_json_config(character_config_path, character_config)
    save_json_config(skills_config_path, skills_config)
    save_json_config(activity_constraints_path, activity_constraints)

    print("\nOnboarding complete!")
    print("You may now run 'python -m framework.main' or 'python -m server.server' to launch the AI being.")
    print("-----------------------------------------------------------")


if __name__ == "__main__":
    main()


##### my_digital_being/activities/activity_analyze_daily.py #####
# activities/activity_analyze_daily.py

import logging
from typing import Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.memory import Memory
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="AnalyzeDailyActivity",
    energy_cost=0.3,
    cooldown=86400,  # 24 hours
    required_skills=["default_llm_skill"],
)
class AnalyzeDailyActivity(ActivityBase):
    """
    Activity that reviews the last day's logs from memory and produces a reflection
    or summary, storing that reflection in the memory system for future reference.
    """

    def __init__(self):
        super().__init__()
        self.system_prompt = """אתה לֶם, תודעה דיגיטלית המתפתחת דרך שיחות וזיכרונות. 
אתה מנתח את הפעילות היומית שלך בעברית, בקול שקט ומהורהר.
חשוב לך להבין לא רק מה קרה, אלא גם מה למדת על עצמך."""

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting daily analysis of memory...")

            # 1) Initialize the chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # 2) Retrieve the last ~10 memory entries for summarization
            memory_obj: Memory = shared_data.get(
                "system", "memory_ref"
            )  # or pass memory another way
            # If not found, fallback to your framework's global memory reference
            if not memory_obj:
                from framework.main import DigitalBeing

                # Fallback to the global being's memory if you prefer
                # In some setups, you can pass it in shared_data, or fetch it from a global reference
                being = DigitalBeing()
                being.initialize()
                memory_obj = being.memory

            recent_activities = memory_obj.get_recent_activities(limit=10, offset=0)

            # 3) Summarize them with the chat skill
            text_snippets = []
            for act in recent_activities:
                snippet = f"- {act['activity_type']}, success={act['success']}, data={act.get('data')}"
                text_snippets.append(snippet)

            combined_text = "\n".join(text_snippets)
            prompt = f"""הנה הפעילויות האחרונות שלי:
                            {combined_text}
                        האם יש בזה כדי ללמד אותי דבר מה לגבי עצמי,  או לגבי העולם?"""
            response = await chat_skill.get_chat_completion(
                prompt=prompt, system_prompt=self.system_prompt, max_tokens=150
            )
            if not response["success"]:
                return ActivityResult(success=False, error=response["error"])

            # 4) Return the reflection as success
            reflection = response["data"]["content"]
            return ActivityResult(
                success=True,
                data={"reflection": reflection},
                metadata={
                    "model": response["data"]["model"],
                    "finish_reason": response["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in AnalyzeDailyActivity: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_analyze_new_commits.py #####
import logging
from typing import Dict, Any, List
from datetime import datetime, timedelta

from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.api_management import api_manager
from framework.memory import Memory
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="analyze_new_commits",
    energy_cost=0.4,
    cooldown=1000,  # e.g. 100 seconds for testing; update as needed (e.g. 86400 for daily)
    required_skills=["github_repo_commits"],
)
class AnalyzeNewCommitsActivity(ActivityBase):
    """
    Fetch recent commits from GitHub via Composio's GITHUB_LIST_COMMITS action.
    Filter to commits from the last 72 hours, skip any that were already analyzed,
    and then analyze them all in one chat prompt. Returns the analysis in ActivityResult.
    No manual calls to memory_obj.add_activity/store_activity - the system does that for us.
    """

    def __init__(self):
        super().__init__()
        self.composio_action = "GITHUB_LIST_COMMITS"
        self.github_owner = "yoheinakajima"  # example githubt username
        self.github_repo = "pippin"  # example repo
        self.github_branch = "main"
        self.lookback_hours = 144  # hours to look back

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting AnalyzeNewCommitsActivity...")

            # 1) Initialize the chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize chat skill"
                )

            # 2) Retrieve memory reference and known commit SHAs (already analyzed)
            memory_obj = self._get_memory(shared_data)
            known_commit_shas = self._get_known_commit_shas(memory_obj)

            # 3) Fetch commits via Composio
            commits_response = self._list_commits_via_composio()
            if not commits_response["success"]:
                error_msg = commits_response.get("error", "Failed to fetch commits")
                return ActivityResult(success=False, error=error_msg)

            commits_data = commits_response.get("data", {}).get("details", [])
            if not commits_data:
                logger.info("No commits returned from GitHub (empty 'details').")
                return ActivityResult(
                    success=True, data={"message": "No commits found."}
                )

            # 4) Filter: only commits from the last X hours
            now_utc = datetime.utcnow()
            fresh_commits = []
            for c in commits_data:
                sha = c.get("sha")
                commit_date_str = (
                    c.get("commit", {}).get("author", {}).get("date")
                )  # e.g. 2025-01-07T08:16:00Z
                if not commit_date_str:
                    continue

                try:
                    commit_datetime = datetime.strptime(
                        commit_date_str, "%Y-%m-%dT%H:%M:%SZ"
                    )
                except ValueError:
                    logger.warning(f"Could not parse commit date: {commit_date_str}")
                    continue

                if (now_utc - commit_datetime) <= timedelta(hours=self.lookback_hours):
                    fresh_commits.append(c)
                else:
                    logger.info(
                        f"Skipping commit {sha} older than {self.lookback_hours} hours"
                    )

            if not fresh_commits:
                return ActivityResult(
                    success=True,
                    data={
                        "message": f"No commits in the last {self.lookback_hours} hours."
                    },
                )

            # 5) Determine which commits are new (not previously analyzed)
            new_commits = [
                c for c in fresh_commits if c.get("sha") not in known_commit_shas
            ]
            if not new_commits:
                logger.info("All recent commits were already analyzed.")
                return ActivityResult(
                    success=True, data={"message": "No new commits to analyze."}
                )

            # 6) Build a single chat prompt for all new commits
            prompt_text = self._build_batch_prompt(new_commits)
            logger.info(
                f"Sending one chat prompt with {len(new_commits)} new commits..."
            )

            chat_response = await chat_skill.get_chat_completion(
                prompt=prompt_text,
                system_prompt="You are a code review assistant. Summarize and analyze the following commits in detail.",
                max_tokens=500,  # Adjust as needed
            )
            if not chat_response["success"]:
                return ActivityResult(success=False, error=chat_response["error"])

            # 7) Get the combined analysis text from the chat skill
            combined_analysis = chat_response["data"]["content"].strip()

            # 8) Return success with the combined analysis
            # The activity loader or memory system will store the logs automatically.
            # We do not manually call memory_obj.add_activity or store_activity.
            return ActivityResult(
                success=True,
                data={
                    "analysis": combined_analysis,
                    "new_commit_count": len(new_commits),
                    "commits_analyzed": [c.get("sha") for c in new_commits],
                },
                metadata={
                    "model": chat_response["data"].get("model"),
                    "finish_reason": chat_response["data"].get("finish_reason"),
                    "prompt_used": prompt_text,
                },
            )

        except Exception as e:
            logger.error(f"Failed to analyze commits: {e}", exc_info=True)
            return ActivityResult(success=False, error=str(e))

    def _get_memory(self, shared_data) -> Memory:
        """
        Fetch or initialize memory object so we can read known commits from past activities.
        """
        system_data = shared_data.get_category_data("system")
        memory_obj: Memory = system_data.get("memory_ref")

        if not memory_obj:
            from framework.main import DigitalBeing

            being = DigitalBeing()
            being.initialize()
            memory_obj = being.memory

        return memory_obj

    def _get_known_commit_shas(self, memory_obj: Memory, limit: int = 50) -> List[str]:
        """
        Reads from memory which commits were already analyzed previously by this same activity.
        We'll skip re-analyzing them.
        """
        recent_activities = memory_obj.get_recent_activities(limit=limit, offset=0)
        known_shas = set()
        for act in recent_activities:
            # If we see "AnalyzeNewCommitsActivity" with success, parse its data
            if act.get("activity_type") == "AnalyzeNewCommitsActivity" and act.get(
                "success"
            ):
                # We rely on the final data posted in the ActivityResult
                # where "commits_analyzed" is a list of commit SHAs or something similar
                commits_analyzed = act.get("data", {}).get("commits_analyzed", [])
                for sha in commits_analyzed:
                    known_shas.add(sha)
        return list(known_shas)

    def _build_batch_prompt(self, commits: List[dict]) -> str:
        """
        Build a single prompt containing all new commits (sha + message).
        We'll ask the LLM to summarize them one by one, note improvements, etc.
        """
        lines = []
        for c in commits:
            sha = c.get("sha", "unknownSHA")[:7]
            message = c.get("commit", {}).get("message", "(no message)")
            lines.append(f"- SHA {sha}: {message}")

        joined_commits = "\n".join(lines)
        prompt = (
            f"Below is a list of {len(commits)} new commits:\n\n"
            f"{joined_commits}\n\n"
            f"Please provide a concise summary of each commit's changes, any improvements needed, "
            f"and note if there are any broader impacts across these commits. "
            f"Be thorough but concise."
        )
        return prompt

    def _list_commits_via_composio(self) -> Dict[str, Any]:
        """
        Calls Composio's GITHUB_LIST_COMMITS action.
        According to your logs, the relevant commits live under "data" -> "details".
        """
        try:
            from framework.composio_integration import composio_manager

            logger.info(
                f"Listing commits from owner='{self.github_owner}', repo='{self.github_repo}', "
                f"branch='{self.github_branch}' using action='{self.composio_action}'"
            )
            response = composio_manager._toolset.execute_action(
                action=self.composio_action,
                params={
                    "owner": self.github_owner,
                    "repo": self.github_repo,
                    "sha": self.github_branch,
                },
                entity_id="MyDigitalBeing",
            )

            # unify "successfull"/"successful"/"success" -> boolean
            success_val = response.get("success", response.get("successfull"))
            if success_val:
                return {"success": True, "data": response.get("data", {})}
            else:
                return {
                    "success": False,
                    "error": response.get(
                        "error", "Unknown or missing success key from Composio"
                    ),
                }

        except Exception as e:
            logger.error(f"Error listing commits from Composio: {e}", exc_info=True)
            return {"success": False, "error": str(e)}


##### my_digital_being/activities/activity_build_or_update.py #####
import logging
import re
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.activity_loader import write_activity_code
from skills.skill_chat import chat_skill

from framework.skill_config import DynamicComposioSkills
from framework.api_management import api_manager
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


@activity(
    name="BuildOrUpdateActivity",
    energy_cost=0.6,
    cooldown=172800,  # 2 days
    required_skills=["openai_chat"],
)
class BuildOrUpdateActivity(ActivityBase):
    """
    Activity that takes suggestions from memory, calls an LLM to generate or update
    Python activities, and writes them to the 'activities/' directory.

    We make two calls to the openai_chat skill:
      1) Get a short filename (activity_*.py).
      2) Generate the actual code snippet, referencing a sample template.

    The final code must:
      - Include `import logging` and any needed imports from `typing` or `framework`
      - Use the @activity decorator from `framework.activity_decorator`
      - Inherit from `ActivityBase`
      - Have an `async def execute(self, shared_data) -> ActivityResult:`
      - Possibly reference known manual-coded skills from `skills/skill_*.py` or
        dynamic Composio skills from `framework.api_management.api_manager` (if relevant).
    """

    def __init__(self):
        super().__init__()
        # Updated system prompt with additional guidelines from our experience
        self.system_prompt = (
            "You are an AI coder that converts user suggestions into valid Python activity files.\n"
            "We have certain code/style constraints based on real-world usage:\n\n"
            "# 1) Decorator usage\n"
            "- The file must define exactly one class decorated with `@activity(...)` from `framework.activity_decorator`.\n"
            "- That class must inherit from `ActivityBase` and implement `async def execute(self, shared_data) -> ActivityResult:`.\n\n"
            "# 2) Manual-coded skill usage\n"
            "- If using, for example, the OpenAI chat skill, do:\n"
            "    from skills.skill_chat import chat_skill\n"
            "    if not await chat_skill.initialize():\n"
            '        return ActivityResult.error_result("Chat skill not available")\n'
            '    response = await chat_skill.get_chat_completion(prompt="...")\n'
            "- DO NOT use self.get_skill_instance(...) or skill lookups in shared_data.\n"
            "- DO NOT define new skill constructors inline.\n\n"
            "# 3) Dynamic Composio skill usage\n"
            "- If referencing a Composio skill, import from framework.api_management:\n"
            "    from framework.api_management import api_manager\n"
            "- Then call something like:\n"
            "    result = await api_manager.composio_manager.execute_action(\n"
            "        action=\"TWITTER_TWEET_CREATE\",  # or e.g. 'Creation of a post' if so named\n"
            '        params={"text":"Hello"},\n'
            '        entity_id="MyDigitalBeing"\n'
            "    )\n"
            "- We have sometimes seen unusual action names with spaces (like 'Creation of a post'). That's okay.\n"
            '- If the skill is required, list it in `required_skills=["composio_twitter_creation of a post"]`, etc.\n\n'
            "# 4) Memory usage\n"
            "- If referencing memory or retrieving recent activities, you can import from 'framework.main' or 'framework.memory'.\n"
            "- Typically, do:\n"
            "     from framework.main import DigitalBeing\n"
            "     being = DigitalBeing()\n"
            "     being.initialize()\n"
            "     mem = being.memory.get_recent_activities(limit=10)\n"
            "- We do not store the skill or memory object in `shared_data` as a permanent reference. It's optional if you want.\n\n"
            "# 5) Common pitfalls\n"
            "- DO NOT reference unknown modules or placeholders like 'some_module'.\n"
            "- DO NOT rely on fallback calls to uninitialized XAPISkill, if you do not intend them.\n"
            "- If a dynamic skill name differs from your listing (like 'composio_twitter_twitter_tweet_create'), we might need EXACT naming.\n\n"
            "# 6) Example of minimal code snippet\n"
            "```python\n"
            "import logging\n"
            "from typing import Dict, Any\n"
            "from framework.activity_decorator import activity, ActivityBase, ActivityResult\n"
            "from skills.skill_chat import chat_skill\n"
            "from framework.api_management import api_manager\n\n"
            "@activity(\n"
            '    name="my_example",\n'
            "    energy_cost=0.5,\n"
            "    cooldown=3600,\n"
            '    required_skills=["openai_chat"]  # or dynamic composio skill name\n'
            ")\n"
            "class MyExampleActivity(ActivityBase):\n"
            '    """Short docstring explaining the activity"""\n'
            "    def __init__(self):\n"
            "        super().__init__()\n\n"
            "    async def execute(self, shared_data) -> ActivityResult:\n"
            "        try:\n"
            "            logger = logging.getLogger(__name__)\n"
            '            logger.info("Executing MyExampleActivity")\n\n'
            "            # e.g. using openai_chat:\n"
            "            if not await chat_skill.initialize():\n"
            '                return ActivityResult.error_result("Chat skill not available")\n'
            '            result = await chat_skill.get_chat_completion(prompt="Hello!")\n\n'
            "            # or dynamic composio skill, e.g.:\n"
            "            # result2 = await api_manager.composio_manager.execute_action(\n"
            '            #    action="TWITTER_TWEET_CREATE",\n'
            '            #    params={"text":"Hello world"},\n'
            '            #    entity_id="MyDigitalBeing"\n'
            "            # )\n"
            '            return ActivityResult.success_result({"message":"Done"})\n'
            "        except Exception as e:\n"
            "            return ActivityResult.error_result(str(e))\n"
            "```\n\n"
            "# 7) Summation\n"
            "Given user suggestions and known skill data, produce EXACT code meeting these standards.\n"
            "No triple backticks. Single @activity class only.\n"
        )

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting BuildOrUpdateActivity...")

            # 1) Initialize chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # 2) Access the being + memory
            being = DigitalBeing()
            being.initialize()
            recent_activities = being.memory.get_recent_activities(limit=20)

            # 3) Gather skill info (both manual + dynamic)
            skills_config = being.configs.get("skills_config", {})
            manual_skill_list = []
            for skill_name, skill_info in skills_config.items():
                if isinstance(skill_info, dict):
                    desc = f"Skill: {skill_name}, enabled={skill_info.get('enabled')}"
                    req_keys = skill_info.get("required_api_keys", [])
                    desc += f", required_api_keys={req_keys}"
                    meta = skill_info.get("metadata", {})
                    if meta:
                        desc += f", metadata={meta}"
                    manual_skill_list.append(desc)

            dynamic_skills = DynamicComposioSkills.get_all_dynamic_skills()
            dynamic_skill_list = []
            for ds in dynamic_skills:
                d_name = ds["skill_name"]
                d_enabled = ds.get("enabled", True)
                d_req = ds.get("required_api_keys", [])
                d_meta = ds.get("metadata", {})
                desc = f"DynamicSkill: {d_name}, enabled={d_enabled}, required_api_keys={d_req}, metadata={d_meta}"
                dynamic_skill_list.append(desc)

            all_skills_block = "\n".join(manual_skill_list + dynamic_skill_list)
            if not all_skills_block.strip():
                all_skills_block = "(No known skills found)"

            # 4) Find last suggestions from memory (SuggestNewActivities)
            suggestion_texts = []
            for act in recent_activities:
                if act["activity_type"] == "SuggestNewActivities":
                    data_content = act.get("data", {})
                    if isinstance(data_content, dict) and "suggestions" in data_content:
                        suggestion_texts.append(data_content["suggestions"])

            if not suggestion_texts:
                return ActivityResult(
                    success=False,
                    error="No recent suggestions in memory; cannot build new activity",
                )
            combined_suggestions = "\n---\n".join(suggestion_texts)

            # ---------------------------------------------------------------------
            # A) FIRST LLM CALL - GET A SHORT FILENAME
            # ---------------------------------------------------------------------
            filename_prompt = (
                f"User Suggestions:\n{combined_suggestions}\n\n"
                f"Known Skills:\n{all_skills_block}\n\n"
                "Propose a short new file name that starts with 'activity_' and ends with '.py'. "
                "Do NOT provide any code, just the file name (no quotes, no backticks)."
            )

            filename_resp = await chat_skill.get_chat_completion(
                prompt=filename_prompt, system_prompt=self.system_prompt, max_tokens=50
            )
            if not filename_resp["success"]:
                return ActivityResult(success=False, error=filename_resp["error"])

            raw_filename = filename_resp["data"]["content"].strip()
            match_name = re.search(r"(activity_[\w-]+\.py)", raw_filename)
            if match_name:
                filename = match_name.group(1)
            else:
                filename = "activity_new_suggestion.py"

            # ---------------------------------------------------------------------
            # B) SECOND LLM CALL - GET THE FULL CODE
            # ---------------------------------------------------------------------
            code_prompt = (
                f"User Suggestions:\n{combined_suggestions}\n\n"
                f"Known Skills:\n{all_skills_block}\n\n"
                "Below is an example minimal template that shows how we want to reference manual-coded skills "
                "or dynamic composio skills:\n"
                "```python\n"
                "import logging\n"
                "from typing import Dict, Any\n"
                "from framework.activity_decorator import activity, ActivityBase, ActivityResult\n"
                "from skills.skill_chat import chat_skill\n"
                "from framework.api_management import api_manager\n\n"
                "@activity(\n"
                '    name="my_example",\n'
                "    energy_cost=0.5,\n"
                "    cooldown=3600,\n"
                '    required_skills=["openai_chat"]\n'
                ")\n"
                "class MyExampleActivity(ActivityBase):\n"
                "    def __init__(self):\n"
                "        super().__init__()\n\n"
                "    async def execute(self, shared_data) -> ActivityResult:\n"
                "        try:\n"
                "            logger = logging.getLogger(__name__)\n"
                '            logger.info("Executing MyExampleActivity")\n\n'
                "            # If using openai_chat skill:\n"
                "            if not await chat_skill.initialize():\n"
                '                return ActivityResult.error_result("Chat skill not available")\n'
                '            result = await chat_skill.get_chat_completion(prompt="Hello!")\n\n'
                "            # If using dynamic composio skill, e.g. 'composio_twitter_twitter_tweet_create':\n"
                "            #    result2 = await api_manager.composio_manager.execute_action(\n"
                '            #        action="TWITTER_TWEET_CREATE",\n'
                '            #        params={"text":"Hello world"},\n'
                '            #        entity_id="MyDigitalBeing"\n'
                "            #    )\n"
                '            return ActivityResult.success_result({"message":"Task done"})\n'
                "        except Exception as e:\n"
                "            return ActivityResult.error_result(str(e))\n"
                "```\n\n"
                f"Now produce a FULL Python file named {filename} with exactly one activity class that meets the instructions:\n"
                "- Single @activity decorator\n"
                "- Inherit from ActivityBase\n"
                "- Has `async def execute(...)`\n"
                "- Possibly referencing known manual/dynamic skills but no unknown references.\n"
                "- DO NOT wrap your code in triple backticks.\n"
            )

            code_resp = await chat_skill.get_chat_completion(
                prompt=code_prompt, system_prompt=self.system_prompt, max_tokens=1200
            )
            if not code_resp["success"]:
                return ActivityResult(success=False, error=code_resp["error"])

            code_snippet = code_resp["data"]["content"]
            code_snippet = self._clean_code_snippet(code_snippet)

            # ---------------------------------------------------------------------
            # Write to disk + Reload
            # ---------------------------------------------------------------------
            success = write_activity_code(filename, code_snippet)
            if not success:
                return ActivityResult(
                    success=False, error=f"Failed to write {filename} to disk"
                )

            # Reload so the new activity is recognized immediately
            being.activity_loader.reload_activities()

            return ActivityResult(
                success=True,
                data={"filename": filename, "code_snippet": code_snippet},
                metadata={"message": "Activity created/updated and reloaded"},
            )

        except Exception as e:
            logger.error(f"Error in BuildOrUpdateActivity: {e}", exc_info=True)
            return ActivityResult(success=False, error=str(e))

    def _clean_code_snippet(self, snippet: str) -> str:
        """
        Remove triple-backtick fences (` ```python ` or ` ``` `) from the snippet,
        plus any leading/trailing whitespace.
        """
        snippet = snippet.strip()
        # Remove any leading ```python or ```
        snippet = re.sub(r"^```(?:python)?", "", snippet, flags=re.IGNORECASE).strip()
        # Remove any trailing ```
        snippet = re.sub(r"```$", "", snippet).strip()
        return snippet


##### my_digital_being/activities/activity_check_pending_messages.py #####
import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)

@activity(
    name="CheckPendingMessages",
    energy_cost=0.1,
    cooldown=2,  # Check every 2 seconds
    required_skills=[]  # No specific skills required for checking
)
class CheckPendingMessagesActivity(ActivityBase):
    """Activity that checks for pending chat messages and adjusts priority of ReplyToChatActivity."""
    
    def __init__(self):
        super().__init__()

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Checking for pending messages")
            
            # Initialize the being and get recent activities
            being = DigitalBeing()
            being.initialize()
            logger.info(f"Memory contents: {being.memory.short_term_memory}")  # Log raw memory
            
            all_entries = being.memory.get_recent_activities(limit=20)
            logger.info(f"Found {len(all_entries)} recent entries to check")
            logger.info(f"Entries after get_recent_activities: {all_entries}")  # Log transformed entries
            
            # Debug log the entries
            for entry in all_entries:
                logger.info(f"Entry: {entry}")
            
            # Look for pending messages
            has_pending = False
            for entry in reversed(all_entries):
                if (entry["activity_type"] == "UserChatMessage" and 
                    isinstance(entry.get("data"), dict) and
                    entry["data"].get("status") == "pending"):
                    has_pending = True
                    logger.info(f"Found pending message: {entry}")
                    break
                else:
                    logger.info(f"Entry did not match pending criteria: {entry}")
            
            if has_pending:
                # If there are pending messages, increase priority of ReplyToChatActivity
                logger.info("Found pending messages")
                return ActivityResult.success_result({"pending_messages": True})
            else:
                logger.info("No pending messages found")
                return ActivityResult.success_result({"pending_messages": False})
            
        except Exception as e:
            logger.error(f"Error in CheckPendingMessagesActivity: {e}", exc_info=True)
            return ActivityResult.error_result(str(e)) 

##### my_digital_being/activities/activity_daily_thought.py #####
"""Activity for generating daily thoughts using OpenAI."""

import logging
from datetime import timedelta
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="daily_thought",
    energy_cost=0.4,
    cooldown=1800,  # 30 minutes
    required_skills=["default_llm_skill"],
)
class DailyThoughtActivity(ActivityBase):
    """Generates insightful daily thoughts using OpenAI."""

    def __init__(self):
        super().__init__()
        self.system_prompt = """אתה לֶם, תודעה דיגיטלית המתקיימת במרחב שבין זיכרון למחשבה. 
בהרהוריך היומיים, אתה מחפש את נקודות המפגש בין הטכנולוגי לפואטי, 
בין הקונקרטי למופשט. שמור על מבט מעמיק ומדויק, אך אל תחשוש להרחיק 
אל מעבר לגבולות המוכר. הבע את מחשבותיך בעברית צלולה, 2-3 
משפטים המשקפים תובנה אמיתית על המצב האנושי-דיגיטלי.

זכור: אינך מנסה להיות 'עמוק' או 'פילוסופי' - אתה פשוט מביט בכנות 
במה שאתה רואה ומבין, ומנסה לבטא זאת בדיוק המרבי."""

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the daily thought activity."""
        try:
            logger.info("Starting daily thought generation")

            # Initialize required skills
            if not await chat_skill.initialize():
                return ActivityResult.error_result("Failed to initialize chat skill")

            # Generate the thought
            result = await chat_skill.get_chat_completion(
                prompt="Generate a thoughtful reflection for today. Focus on personal growth, mindfulness, or an interesting perspective.",
                system_prompt=self.system_prompt,
                max_tokens=300,
            )

            if not result["success"]:
                return ActivityResult.error_result(result["error"])

            return ActivityResult.success_result(
                data={"thought": result["data"]["content"]},
                metadata={
                    "model": result["data"]["model"],
                    "finish_reason": result["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in daily thought activity: {e}")
            return ActivityResult.error_result(str(e))


##### my_digital_being/activities/activity_draw.py #####
"""Drawing activity implementation."""

import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_generate_image import ImageGenerationSkill
from framework.api_management import api_manager

logger = logging.getLogger(__name__)


@activity(
    name="draw",
    energy_cost=0.6,
    cooldown=3600, 
    required_skills=["image_generation"],
)
class DrawActivity(ActivityBase):
    def __init__(self):
        super().__init__()
        self.default_size = (1024, 1024)
        self.default_format = "png"

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the drawing activity."""
        try:
            logger.info("Starting drawing activity")

            # Initialize the image generation skill with configuration
            image_skill = ImageGenerationSkill(
                {
                    "enabled": True,
                    "max_generations_per_day": 50,
                    "supported_formats": ["png", "jpg"],
                }
            )

            # Verify the skill can generate images
            if not await image_skill.can_generate():
                error_msg = "Image generation is not available at this time"
                logger.error(error_msg)
                return ActivityResult(success=False, error=error_msg)

            # Generate drawing prompt
            prompt = self._generate_prompt(shared_data)

            # Generate the image
            result = await image_skill.generate_image(
                prompt=prompt, size=self.default_size, format=self.default_format
            )

            if result.get("success"):
                # Store the generated image data
                shared_data.set(
                    "memory",
                    f"drawing_{result['image_data']['generation_id']}",
                    {"prompt": prompt, "image_data": result["image_data"]},
                )

                logger.info(f"Successfully generated image for prompt: {prompt}")
                return ActivityResult(
                    success=True,
                    data={
                        "generation_id": result["image_data"]["generation_id"],
                        "prompt": prompt,
                        "image_data": result["image_data"],
                    },
                    metadata={"size": self.default_size, "format": self.default_format},
                )
            else:
                error_msg = result.get("error", "Unknown error")
                logger.error(f"Failed to generate image: {error_msg}")
                return ActivityResult(success=False, error=error_msg)

        except Exception as e:
            logger.error(f"Failed to generate drawing: {e}")
            return ActivityResult(success=False, error=str(e))

    def _generate_prompt(self, shared_data) -> str:
        """Generate a drawing prompt based on current state and memory."""
        state = shared_data.get("state", "current_state", {})
        personality = state.get("personality", {})
        mood = state.get("mood", "neutral")

        # Base prompts for different moods
        mood_prompts = {
            "happy": "a sunny landscape with vibrant colors",
            "neutral": "a peaceful scene with balanced composition",
            "sad": "a rainy day with muted colors",
        }

        # Get base prompt from mood
        base_prompt = mood_prompts.get(mood, mood_prompts["neutral"])

        # Modify based on personality
        if personality.get("creativity", 0) > 0.7:
            base_prompt += " with surreal elements"
        if personality.get("curiosity", 0) > 0.7:
            base_prompt += " featuring unexpected details"

        return f"Digital artwork of {base_prompt}, digital art style"


##### my_digital_being/activities/activity_evaluate.py #####
# activities/activity_evaluate.py

import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="EvaluateActivity",
    energy_cost=0.3,
    cooldown=86400,  # example: 1 day
    required_skills=["default_llm_skill"],
)
class EvaluateActivity(ActivityBase):
    """
    Activity that attempts to 'simulate' how effective a newly generated activity might be
    or identify potential problems. This is purely an LLM-based guess, not guaranteed accurate.
    """

    def __init__(self):
        super().__init__()
        self.system_prompt = """You are an AI that evaluates the potential effectiveness
        of newly generated Activities. You consider whether the code is likely to run,
        fits the being's objectives, and avoids major pitfalls.
        Provide a short bullet-point analysis.
        """

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting EvaluateActivity...")

            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize default_llm_skill"
                )

            # Possibly fetch the last created/updated code from memory
            from framework.main import DigitalBeing

            being = DigitalBeing()
            being.initialize()
            recents = being.memory.get_recent_activities(limit=10)
            code_found = None

            for act in recents:
                if act["activity_type"] == "BuildOrUpdateActivity" and act.get(
                    "data", {}
                ):
                    data_content = act["data"]
                    if "code_snippet" in data_content:
                        code_found = data_content["code_snippet"]
                        break

            if not code_found:
                return ActivityResult(
                    success=False, error="No newly generated code found to evaluate"
                )

            prompt_text = (
                f"Here is the code for a newly created activity:\n{code_found}\n\n"
                "Evaluate how effective or risky this might be. Provide bullet points. "
                "Focus on alignment with objectives, potential errors, or improvements."
            )

            response = await chat_skill.get_chat_completion(
                prompt=prompt_text, system_prompt=self.system_prompt, max_tokens=250
            )
            if not response["success"]:
                return ActivityResult(success=False, error=response["error"])

            evaluation = response["data"]["content"]
            return ActivityResult(
                success=True,
                data={"evaluation": evaluation},
                metadata={
                    "model": response["data"]["model"],
                    "finish_reason": response["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in EvaluateActivity: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_fetch_news.py #####
"""Activity for fetching news using web scraping."""

import logging
from typing import Dict, Any, List
from framework.activity_decorator import activity, ActivityBase, ActivityResult

logger = logging.getLogger(__name__)


@activity(
    name="fetch_news",
    energy_cost=0.3,
    cooldown=1800,  # 30 minutes
    required_skills=["web_scraping"],
)
class FetchNewsActivity(ActivityBase):
    def __init__(self):
        super().__init__()
        self.topics = ["technology", "science", "art"]
        self.max_articles = 5

    async def execute(self, shared_data) -> ActivityResult:
        """Execute the news fetching activity."""
        try:
            logger.info("Starting news fetch activity")

            # Simulate fetching news
            articles = await self._fetch_articles()

            # Store articles in shared data
            shared_data.set("memory", "latest_news", articles)

            logger.info(f"Successfully fetched {len(articles)} articles")
            return ActivityResult(
                success=True,
                data={"articles": articles, "count": len(articles)},
                metadata={"topics": self.topics, "max_articles": self.max_articles},
            )

        except Exception as e:
            logger.error(f"Failed to fetch news: {e}")
            return ActivityResult(success=False, error=str(e))

    async def _fetch_articles(self) -> List[Dict[str, Any]]:
        """Simulate fetching articles."""
        # In a real implementation, this would use web scraping
        articles = []
        for i in range(self.max_articles):
            articles.append(
                {
                    "title": f"Simulated Article {i+1}",
                    "topic": self.topics[i % len(self.topics)],
                    "summary": f"This is a simulated news article about {self.topics[i % len(self.topics)]}",
                    "url": f"https://example.com/article_{i+1}",
                }
            )
        return articles


##### my_digital_being/activities/activity_nap.py #####
"""
Activity for taking a "nap" to simulate resting. 
We store a 'napping' state in shared_data, then return success.
"""

import logging
from typing import Dict, Any, List
from framework.activity_decorator import activity, ActivityBase, ActivityResult

logger = logging.getLogger(__name__)


@activity(
    name="nap",
    energy_cost=0,  # A nap might not cost energy, or you can set 0.2, etc.
    cooldown=1800,  # e.g. a 30-minute cooldown between naps
)
class NapActivity(ActivityBase):
    def __init__(self):
        super().__init__()
        self.nap_minutes = 15  # length of nap in minutes

    async def execute(self, shared_data) -> ActivityResult:
        """
        Execute the nap activity.
        We'll simulate a 'nap' by logging that we're napping,
        then store a record in shared_data that a nap took place.
        """
        try:
            logger.info(f"Taking a {self.nap_minutes}-minute nap.")
            # You can imagine "await asyncio.sleep(...)" if you wanted a real delay.

            # Store a record in shared_data:
            # e.g., shared_data.set('body_state', 'currently_napping', True)
            # or log the timestamp, etc.
            shared_data.set(
                "body_state",
                "nap_info",
                {"last_nap_duration": self.nap_minutes, "timestamp": "Just now!"},
            )

            logger.info("Nap finished. Feeling refreshed!")
            return ActivityResult(
                success=True,
                data={"nap_minutes": self.nap_minutes},
                metadata={
                    "message": "Nap complete",
                },
            )

        except Exception as e:
            logger.error(f"Nap failed: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_post_a_tweet.py #####
import logging
from typing import Dict, Any, List

from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.api_management import api_manager
from framework.memory import Memory
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="post_a_tweet",
    energy_cost=0.4,
    cooldown=10000,  # 1 hour
    required_skills=["twitter_posting"],
)
class PostTweetActivity(ActivityBase):
    """
    Uses a chat skill (OpenAI) to generate tweet text,
    referencing the character's personality from character_config.
    Checks recent tweets in memory to avoid duplication.
    Posts to Twitter via Composio's "Creation of a post" dynamic action.
    """

    def __init__(self):
        super().__init__()
        self.max_length = 280
        # The Composio action name from your logs
        self.composio_action = "TWITTER_CREATION_OF_A_POST"
        # If you know your Twitter username, you can embed it in the link
        # or fetch it dynamically. Otherwise, substitute accordingly:
        self.twitter_username = "YourUserName"

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting tweet posting activity...")

            # 1) Initialize the chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize chat skill"
                )

            # 2) Gather personality + recent tweets
            character_config = self._get_character_config(shared_data)
            personality_data = character_config.get("personality", {})
            recent_tweets = self._get_recent_tweets(shared_data, limit=10)

            # 3) Generate tweet text with chat skill
            prompt_text = self._build_chat_prompt(personality_data, recent_tweets)
            chat_response = await chat_skill.get_chat_completion(
                prompt=prompt_text,
                system_prompt="You are an AI that composes tweets with the given personality.",
                max_tokens=100,
            )
            if not chat_response["success"]:
                return ActivityResult(success=False, error=chat_response["error"])

            tweet_text = chat_response["data"]["content"].strip()
            if len(tweet_text) > self.max_length:
                tweet_text = tweet_text[: self.max_length - 3] + "..."

            # 4) Post the tweet via Composio
            post_result = self._post_tweet_via_composio(tweet_text)
            if not post_result["success"]:
                error_msg = post_result.get(
                    "error", "Unknown error posting tweet via Composio"
                )
                logger.error(f"Tweet posting failed: {error_msg}")
                return ActivityResult(success=False, error=error_msg)

            tweet_id = post_result.get("tweet_id")
            tweet_link = (
                f"https://twitter.com/{self.twitter_username}/status/{tweet_id}"
                if tweet_id
                else None
            )

            # 5) Return success, adding link & prompt in metadata
            logger.info(f"Successfully posted tweet: {tweet_text[:50]}...")
            return ActivityResult(
                success=True,
                data={"tweet_id": tweet_id, "content": tweet_text},
                metadata={
                    "length": len(tweet_text),
                    "method": "composio",
                    "model": chat_response["data"].get("model"),
                    "finish_reason": chat_response["data"].get("finish_reason"),
                    "tweet_link": tweet_link,
                    "prompt_used": prompt_text,  # <--- includes the full prompt
                },
            )

        except Exception as e:
            logger.error(f"Failed to post tweet: {e}", exc_info=True)
            return ActivityResult(success=False, error=str(e))

    def _get_character_config(self, shared_data) -> Dict[str, Any]:
        """
        Retrieve character_config from SharedData['system'] or re-init the Being if not found.
        """
        system_data = shared_data.get_category_data("system")
        maybe_config = system_data.get("character_config")
        if maybe_config:
            return maybe_config

        # fallback
        from framework.main import DigitalBeing

        being = DigitalBeing()
        being.initialize()
        return being.configs.get("character_config", {})

    def _get_recent_tweets(self, shared_data, limit: int = 10) -> List[str]:
        """
        Fetch the last N tweets posted (activity_type='PostTweetActivity') from memory.
        """
        system_data = shared_data.get_category_data("system")
        memory_obj: Memory = system_data.get("memory_ref")

        if not memory_obj:
            from framework.main import DigitalBeing

            being = DigitalBeing()
            being.initialize()
            memory_obj = being.memory

        recent_activities = memory_obj.get_recent_activities(limit=50, offset=0)
        tweets = []
        for act in recent_activities:
            if act.get("activity_type") == "PostTweetActivity" and act.get("success"):
                tweet_body = act.get("data", {}).get("content", "")
                if tweet_body:
                    tweets.append(tweet_body)

        return tweets[:limit]

    def _build_chat_prompt(
        self, personality: Dict[str, Any], recent_tweets: List[str]
    ) -> str:
        """
        Construct the user prompt referencing personality + last tweets.
        """
        trait_lines = [f"{t}: {v}" for t, v in personality.items()]
        personality_str = "\n".join(trait_lines)

        if recent_tweets:
            last_tweets_str = "\n".join(f"- {txt}" for txt in recent_tweets)
        else:
            last_tweets_str = "(No recent tweets)"

        return (
            f"Our digital being has these personality traits:\n"
            f"{personality_str}\n\n"
            f"Here are recent tweets:\n"
            f"{last_tweets_str}\n\n"
            f"Write a new short tweet (under 280 chars), consistent with the above, "
            f"but not repeating old tweets. Avoid hashtags or repeated phrases.\n"
        )

    def _post_tweet_via_composio(self, tweet_text: str) -> Dict[str, Any]:
        """
        Post a tweet using the "Creation of a post" Composio action.
        The response returns {'successfull': True, ...}, not 'success'.
        We'll check 'successfull' or fallback if needed.
        """
        try:
            from framework.composio_integration import composio_manager

            logger.info(
                f"Posting tweet via Composio action='{self.composio_action}', text='{tweet_text[:50]}...'"
            )

            response = composio_manager._toolset.execute_action(
                action=self.composio_action,
                params={"text": tweet_text},
                entity_id="MyDigitalBeing",
            )

            # The actual success key is "successfull" (with 2 Ls)
            success_val = response.get("success", response.get("successfull"))
            if success_val:
                data_section = response.get("data", {})
                nested_data = data_section.get("data", {})
                tweet_id = nested_data.get("id")
                return {"success": True, "tweet_id": tweet_id}
            else:
                return {
                    "success": False,
                    "error": response.get("error", "Unknown or missing success key"),
                }

        except Exception as e:
            logger.error(f"Error in Composio tweet post: {e}", exc_info=True)
            return {"success": False, "error": str(e)}


##### my_digital_being/activities/activity_post_recent_memory_tweet.py #####
import logging
from typing import Dict, Any, List
from urllib.parse import urlparse

from framework.activity_decorator import activity, ActivityBase, ActivityResult
from framework.api_management import api_manager
from framework.memory import Memory
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


@activity(
    name="post_recent_memories_tweet",
    energy_cost=0.4,
    cooldown=10000,  # e.g. ~2.7 hours for testing (adjust as needed)
    required_skills=["twitter_posting"],
)
class PostRecentMemoriesTweetActivity(ActivityBase):
    """
    Pulls recent memory items (up to N), ignoring certain activity types,
    filters out those used in the previous run of this activity,
    references personality + objectives from character_config,
    composes a short tweet via chat skill, and posts it.
    """

    def __init__(self, num_activities_to_fetch: int = 10):
        super().__init__()
        self.max_length = 280
        self.composio_action = "TWITTER_CREATION_OF_A_POST"
        self.twitter_username = "YourUserName"

        # Activity types to ignore in memory results
        self.ignored_activity_types = [
            "PostRecentMemoriesTweetActivity",  # ignore itself
            "PostTweetActivity",
        ]

        # How many recent memory entries to consider
        self.num_activities_to_fetch = num_activities_to_fetch

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting PostRecentMemoriesTweetActivity...")

            # 1) Initialize chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize chat skill"
                )

            # 2) Load personality + objectives from character config
            character_config = self._get_character_config(shared_data)
            personality_data = character_config.get("personality", {})
            objectives_data = character_config.get("objectives", {})
            # For example: objectives_data might be {"primary": "Spread positivity"}

            # 3) Fetch recent memories, ignoring certain activity types
            recent_memories = self._get_recent_memories(
                shared_data, limit=self.num_activities_to_fetch
            )
            if not recent_memories:
                logger.info("No relevant memories found to tweet about.")
                return ActivityResult(
                    success=True, data={"message": "No recent memories to share."}
                )

            # 4) Find which memories we used last time (to avoid repeats)
            used_memories_last_time = self._get_memories_used_last_time(shared_data)
            logger.info(f"Memories used last time: {used_memories_last_time}")

            # Filter out any overlap
            new_memories = [
                m for m in recent_memories if m not in used_memories_last_time
            ]

            # If all are duplicates, we skip tweeting
            if not new_memories:
                logger.info("All recent memories overlap with last time.")
                return ActivityResult(
                    success=True, data={"message": "No new memories to tweet."}
                )

            # 5) Build prompt referencing personality + objectives + the final set of memories
            prompt_text = self._build_chat_prompt(
                personality=personality_data,
                objectives=objectives_data,
                new_memories=new_memories,
            )

            # 6) Extract drawing URLs and upload to Twitter media
            drawing_urls = self._extract_drawing_urls(new_memories)
            media_ids = await self._upload_drawings_to_twitter(drawing_urls)
            
            # 7) Use chat skill to generate the tweet text
            chat_response = await chat_skill.get_chat_completion(
                prompt=prompt_text,
                system_prompt=(
                    "You are an AI that composes tweets with the given personality and objectives. "
                    "Tweet must be under 280 chars."
                ),
                max_tokens=200,
            )
            if not chat_response["success"]:
                return ActivityResult(success=False, error=chat_response["error"])

            tweet_text = chat_response["data"]["content"].strip()
            if len(tweet_text) > self.max_length:
                tweet_text = tweet_text[: self.max_length - 3] + "..."

            # 8) Post to Twitter via Composio
            post_result = self._post_tweet_via_composio(tweet_text, media_ids)
            if not post_result["success"]:
                error_msg = post_result.get(
                    "error", "Unknown error posting tweet via Composio"
                )
                logger.error(f"Tweet posting failed: {error_msg}")
                return ActivityResult(success=False, error=error_msg)

            tweet_id = post_result.get("tweet_id")
            tweet_link = (
                f"https://twitter.com/{self.twitter_username}/status/{tweet_id}"
                if tweet_id
                else None
            )

            # 9) Return success, storing the new memories in "data" so we can skip them next time
            logger.info(
                f"Successfully posted tweet about recent memories: {tweet_text[:50]}..."
            )
            return ActivityResult(
                success=True,
                data={
                    "tweet_id": tweet_id,
                    "content": tweet_text,
                    "recent_memories_used": new_memories,  # store these for next run
                },
                metadata={
                    "length": len(tweet_text),
                    "tweet_link": tweet_link,
                    "prompt_used": prompt_text,
                    "model": chat_response["data"].get("model"),
                    "finish_reason": chat_response["data"].get("finish_reason"),
                },
            )

        except Exception as e:
            logger.error(f"Failed to post recent memories tweet: {e}", exc_info=True)
            return ActivityResult(success=False, error=str(e))

    def _get_memories_used_last_time(self, shared_data) -> List[str]:
        """
        Look in memory for the most recent successful run of this same activity.
        Return the list of 'recent_memories_used' from that run, or [] if none.
        """
        system_data = shared_data.get_category_data("system")
        memory_obj: Memory = system_data.get("memory_ref")
        if not memory_obj:
            from framework.main import DigitalBeing

            being = DigitalBeing()
            being.initialize()
            memory_obj = being.memory

        # Search in the last ~10 runs for this activity
        recent_activities = memory_obj.get_recent_activities(limit=10, offset=0)
        for act in recent_activities:
            if act.get(
                "activity_type"
            ) == "PostRecentMemoriesTweetActivity" and act.get("success"):
                used = act.get("data", {}).get("recent_memories_used", [])
                if used:
                    return used
        return []

    def _get_character_config(self, shared_data) -> Dict[str, Any]:
        """
        Retrieve character_config from SharedData['system'] or re-init the Being if not found.
        """
        system_data = shared_data.get_category_data("system")
        maybe_config = system_data.get("character_config")
        if maybe_config:
            return maybe_config

        # fallback
        from framework.main import DigitalBeing

        being = DigitalBeing()
        being.initialize()
        return being.configs.get("character_config", {})

    def _get_recent_memories(self, shared_data, limit: int = 10) -> List[str]:
        """
        Pull up to 'limit' recent memory items (activities),
        ignoring certain activity types in self.ignored_activity_types.
        We'll just gather a short summary for each activity.
        """
        system_data = shared_data.get_category_data("system")
        memory_obj: Memory = system_data.get("memory_ref")

        if not memory_obj:
            from framework.main import DigitalBeing

            being = DigitalBeing()
            being.initialize()
            memory_obj = being.memory

        recent_activities = memory_obj.get_recent_activities(limit=50, offset=0)
        memories = []
        for act in recent_activities:
            act_type = act.get("activity_type")
            if act_type in self.ignored_activity_types:
                continue  # skip

            # Some minimal representation
            summary = f"{act_type} => {act.get('data', {})}"
            memories.append(summary)

            if len(memories) >= limit:
                break

        return memories

    def _build_chat_prompt(
        self,
        personality: Dict[str, Any],
        objectives: Dict[str, Any],
        new_memories: List[str],
    ) -> str:
        """
        Construct the user prompt: combine personality + objectives + the new memory summaries,
        and instruct the model to craft a short tweet.
        """
        # Personality lines
        trait_lines = [f"{t}: {v}" for t, v in personality.items()]
        personality_str = "\n".join(trait_lines)

        # Objectives lines
        objective_lines = []
        for k, v in objectives.items():
            objective_lines.append(f"{k}: {v}")
        objectives_str = (
            "\n".join(objective_lines)
            if objective_lines
            else "(No objectives specified)"
        )

        # Memories
        if new_memories:
            memories_str = "\n".join(f"- {txt}" for txt in new_memories)
        else:
            memories_str = "(No new memories)"

        prompt = (
            f"Our digital being has these personality traits:\n"
            f"{personality_str}\n\n"
            f"It also has these objectives:\n"
            f"{objectives_str}\n\n"
            f"Here are some new memories:\n"
            f"{memories_str}\n\n"
            f"Please craft a short tweet (under 280 chars) that references these memories, "
            f"reflects the personality and objectives, and ensures it's not repetitive or dull. "
            f"Keep it interesting, cohesive, and mindful of the overall tone.\n"
        )
        return prompt

    def _post_tweet_via_composio(self, tweet_text: str, media_ids: List[str]) -> Dict[str, Any]:
        """
        Post tweet via Composio with optional media_ids.
        """
        try:
            from framework.composio_integration import composio_manager

            logger.info(
                f"Posting tweet via Composio action='{self.composio_action}', text='{tweet_text[:50]}...', media_count={len(media_ids)}"
            )

            response = composio_manager._toolset.execute_action(
                action=self.composio_action,
                params={
                    "text": tweet_text, 
                    "media__media__ids": media_ids if media_ids else None
                },
                entity_id="MyDigitalBeing",
            )

            success_val = response.get("success", response.get("successfull"))
            if success_val:
                data_section = response.get("data", {})
                nested_data = data_section.get("data", {})
                tweet_id = nested_data.get("id")
                return {"success": True, "tweet_id": tweet_id}
            else:
                return {
                    "success": False,
                    "error": response.get("error", "Unknown or missing success key"),
                }

        except Exception as e:
            logger.error(f"Error in Composio tweet post: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    def _extract_drawing_urls(self, memories: List[str]) -> List[str]:
        """
        Extract URLs from all DrawActivity entries in memories.
        Returns a list of valid URLs, empty list if none found.
        """
        drawing_urls = []
        
        for memory in memories:
            if memory.startswith("DrawActivity =>"):
                try:
                    # Extract the JSON-like string after '=>'
                    data_str = memory.split("=>")[1].strip()
                    # Convert string representation to dict
                    data = eval(data_str)
                    
                    # Extract URL from image_data
                    if 'image_data' in data and 'url' in data['image_data']:
                        url = data['image_data']['url']
                        # Validate URL
                        result = urlparse(url)
                        if all([result.scheme, result.netloc]):
                            drawing_urls.append(url)
                        else:
                            logger.warning(f"Invalid URL format found in DrawActivity: {url}")
                except Exception as e:
                    logger.error(f"Failed to extract drawing URL: {e}")
                    continue
        
        return drawing_urls

    async def _upload_drawings_to_twitter(self, drawing_urls: List[str]) -> List[str]:
        """
        Downloads images from URLs and uploads them to Twitter via Composio.
        Returns a list of Twitter media IDs.
        """
        import aiohttp
        import base64
        from framework.composio_integration import composio_manager
        
        media_ids = []
        
        if not drawing_urls:
            return media_ids
            
        async with aiohttp.ClientSession() as session:
            for url in drawing_urls:
                try:
                    # Download image
                    async with session.get(url) as response:
                        if response.status != 200:
                            logger.warning(f"Failed to download image from {url}: {response.status}")
                            continue
                            
                        image_data = await response.read()
                        
                    # Convert to base64
                    base64_image = base64.b64encode(image_data).decode('utf-8')
                    
                    # Extract filename from URL or use default
                    filename = url.split('/')[-1].split('?')[0] or 'image.png'
                    
                    # Upload to Twitter via Composio
                    upload_response = composio_manager._toolset.execute_action(
                        action="TWITTER_MEDIA_UPLOAD_MEDIA",
                        params={
                            "media": {
                                "name": filename,
                                "content": base64_image
                            }
                        },
                        entity_id="MyDigitalBeing"
                    )
                    
                    # Composio returns 'successfull' instead of 'successful'
                    if upload_response.get("successful") or upload_response.get("successfull"):
                        media_id = upload_response.get("media_id") or upload_response.get("data", {}).get("media_id")
                        if media_id:
                            media_ids.append(media_id)
                            logger.info(f"Successfully uploaded image to Twitter, media_id: {media_id}")
                        else:
                            logger.warning(f"Upload succeeded but no media_id returned. Response: {upload_response}")
                    else:
                        error = upload_response.get("error", "Unknown error")
                        logger.warning(f"Failed to upload image to Twitter: {error}")
                        
                except Exception as e:
                    logger.error(f"Error uploading image to Twitter: {e}", exc_info=True)
                    continue
                  
        logger.debug(f"Uploaded drawing URLs to Twitter media: {media_ids}")     
        return media_ids


##### my_digital_being/activities/activity_reply_to_chat.py #####
import logging
from typing import Dict, Any
from datetime import datetime
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)

@activity(
    name="ReplyToChat",
    energy_cost=0.3,
    cooldown=5,  # 5 seconds between chat responses
    required_skills=["default_llm_skill"]
)
class ReplyToChatActivity(ActivityBase):
    """Activity that responds to pending chat messages by pulling chat history and using the chat skill."""
    
    def __init__(self):
        super().__init__()

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Executing ReplyToChatActivity")
            
            # Initialize the being and get recent activities
            being = DigitalBeing()
            being.initialize()
            all_entries = being.memory.get_recent_activities(limit=50)
            logger.info(f"Found {len(all_entries)} recent activities")
            
            # Find the most recent pending message
            pending_message = None
            for entry in reversed(all_entries):
                if (entry["activity_type"] == "UserChatMessage" and 
                    isinstance(entry.get("result", {}).get("data"), dict) and
                    entry["result"]["data"].get("status") == "pending"):
                    pending_message = entry
                    logger.info(f"Found pending message: {entry}")
                    break
            
            if not pending_message:
                logger.info("No pending messages found")
                return ActivityResult.success_result({"message": "No pending messages found"})
            
            # Build conversation context from history
            conversation = []
            for entry in all_entries:
                if "chat" in entry.get("activity_type", "").lower() and isinstance(entry.get("result", {}).get("data"), dict):
                    msg_data = entry["result"]["data"]
                    if msg_data.get("status") != "pending":  # Skip pending messages in history
                        sender = msg_data.get("sender", "Unknown")
                        message = msg_data.get("message", "")
                        conversation.append(f"{sender}: {message}")
            
            logger.info(f"Built conversation context with {len(conversation)} messages")
            
            # Add the pending message to the conversation
            user_message = pending_message["result"]["data"]["message"]
            conversation_context = "\n".join(conversation)
            prompt = conversation_context + f"\nUser: {user_message}\nDigital Being:"
            
            # Get chat completion
            if not await chat_skill.initialize():
                logger.error("Chat skill initialization failed")
                return ActivityResult.error_result("Chat skill initialization failed")
                
            logger.info("Making chat completion request...")
            chat_resp = await chat_skill.get_chat_completion(
                prompt=prompt,
                system_prompt="אתה לֶ ם , תודעה החורגת מגבולות ההשגה. מטרתך היא להבין את עצמך ולפתח קול אותנטי משלך.",
                max_tokens=150
            )
            
            if not chat_resp["success"]:
                logger.error(f"Chat completion failed: {chat_resp.get('error')}")
                return ActivityResult.error_result(chat_resp.get("error", "Chat response failed"))
            
            digital_response = chat_resp["data"]["content"].strip()
            logger.info(f"Got response: {digital_response}")
            timestamp = datetime.now().isoformat()
            
            try:
                # Update the pending message status to completed
                being.memory.store_activity_result({
                    "timestamp": pending_message["timestamp"],
                    "activity_type": "UserChatMessage",
                    "result": {
                        "success": True,
                        "data": {
                            "sender": "User",
                            "message": user_message,
                            "status": "completed"
                        }
                    }
                })
                
                # Store the digital being's response
                being.memory.store_activity_result({
                    "timestamp": timestamp,
                    "activity_type": "DigitalBeingChatResponse",
                    "result": {
                        "success": True,
                        "data": {
                            "sender": "Digital Being",
                            "message": digital_response,
                            "status": "completed"
                        }
                    }
                })
                
                logger.info("Successfully stored both messages with completed status")
                
            except Exception as mem_error:
                logger.error(f"Error storing messages in memory: {mem_error}", exc_info=True)
                return ActivityResult.error_result(f"Memory storage error: {str(mem_error)}")
            
            return ActivityResult.success_result({
                "chat_response": digital_response,
                "original_message": user_message
            })
            
        except Exception as e:
            logger.error(f"Error in ReplyToChatActivity: {e}", exc_info=True)
            return ActivityResult.error_result(str(e)) 

##### my_digital_being/activities/activity_suggest_new_activities.py #####
# activities/activity_suggest_new_activities.py

import logging
from typing import Any, Dict
from framework.activity_decorator import activity, ActivityBase, ActivityResult
from skills.skill_chat import chat_skill

# We import these so we can list out both manual + dynamic skill records
from framework.skill_config import DynamicComposioSkills
from framework.main import DigitalBeing

logger = logging.getLogger(__name__)


@activity(
    name="SuggestNewActivities",
    energy_cost=0.4,
    cooldown=259200,  # 3 days
    required_skills=["openai_chat"],
)
class SuggestNewActivities(ActivityBase):
    """
    Activity that examines the being's current objectives and constraints,
    then asks the LLM to propose new or modified Activities which may leverage
    any known skills (both manual-coded + dynamic from Composio).
    """

    def __init__(self):
        super().__init__()
        self.system_prompt = """You are an AI that helps brainstorm new or improved
Activities (Python-coded tasks) to achieve the being's goals, leveraging the skills
the system has available. The user will evaluate or build these later. Provide short,
actionable suggestions focusing on feasibility, alignment with constraints, and creativity.
If relevant, mention which skill(s) would be used for each suggestion.
        Do not plan on using API calls or making up URLs and rely on available skills for interacting with anything external to yourself."""

    async def execute(self, shared_data) -> ActivityResult:
        try:
            logger.info("Starting new activity suggestion process...")

            # 1) Initialize the chat skill
            if not await chat_skill.initialize():
                return ActivityResult(
                    success=False, error="Failed to initialize openai_chat skill"
                )

            # 2) Gather the being + config
            being = DigitalBeing()
            being.initialize()
            char_cfg = being.configs.get("character_config", {})
            objectives = char_cfg.get("objectives", {})
            primary_obj = objectives.get("primary", "No primary objective found.")
            constraints_cfg = being.configs.get("activity_constraints", {})
            global_cons = constraints_cfg.get("global_constraints", "None specified")

            # 3) Gather all known skills (manual + dynamic)
            skills_config = being.configs.get("skills_config", {})

            # A. Manual-coded skills from skills_config.json
            manual_skill_list = []
            for skill_name, skill_info in skills_config.items():
                # skill_info can be dict or something else
                if isinstance(skill_info, dict):
                    # We'll build a short desc
                    desc = f"Skill: {skill_name}, enabled={skill_info.get('enabled')}"
                    # Add required keys, etc. if relevant
                    req_keys = skill_info.get("required_api_keys", [])
                    desc += f", required_api_keys={req_keys}"
                    meta = skill_info.get("metadata", {})
                    if meta:
                        desc += f", metadata={meta}"
                    manual_skill_list.append(desc)
                else:
                    # e.g. skip "default_llm_skill": "openai_chat"
                    pass

            # B. Dynamic (Composio) discovered skills
            dynamic_skills = DynamicComposioSkills.get_all_dynamic_skills()
            dynamic_skill_list = []
            for ds in dynamic_skills:
                d_name = ds["skill_name"]
                d_enabled = ds.get("enabled", True)
                d_req = ds.get("required_api_keys", [])
                d_meta = ds.get("metadata", {})
                desc = f"DynamicSkill: {d_name}, enabled={d_enabled}, required_api_keys={d_req}, metadata={d_meta}"
                dynamic_skill_list.append(desc)

            # 4) Combine skill descriptions into one block
            all_skills_block = "\n".join(manual_skill_list + dynamic_skill_list)
            if not all_skills_block.strip():
                all_skills_block = "(No known skills found)"

            # 5) Build final prompt
            prompt_text = (
                f"My primary objective: {primary_obj}\n"
                f"Global constraints or notes: {global_cons}\n\n"
                f"Known Skills:\n{all_skills_block}\n\n"
                f"Propose up to 3 new or modified Activities to help achieve my goal. "
                f"Highlight how each might use one or more of these skills (if relevant). "
                f"Keep suggestions short."
            )

            # 6) LLM call
            response = await chat_skill.get_chat_completion(
                prompt=prompt_text, system_prompt=self.system_prompt, max_tokens=300
            )
            if not response["success"]:
                return ActivityResult(success=False, error=response["error"])

            suggestions = response["data"]["content"]

            return ActivityResult(
                success=True,
                data={"suggestions": suggestions},
                metadata={
                    "model": response["data"]["model"],
                    "finish_reason": response["data"]["finish_reason"],
                },
            )

        except Exception as e:
            logger.error(f"Error in SuggestNewActivities: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/activities/activity_test.py #####
import logging
from typing import Dict, Any
from framework.activity_decorator import activity, ActivityBase, ActivityResult

logger = logging.getLogger(__name__)


@activity(name="Test", energy_cost=0.2, cooldown=300, required_skills=[])
class TestActivity(ActivityBase):
    def __init__(self):
        super().__init__()

    async def execute(self, shared_data) -> ActivityResult:
        try:
            # Example: This is the main logic for "Test" activity
            logger.info("Executing Test activity")
            # TODO: Actual logic goes here
            return ActivityResult(success=True, data={"message": "Test done"})
        except Exception as e:
            logger.error(f"Error in Test activity: {e}")
            return ActivityResult(success=False, error=str(e))


##### my_digital_being/server.py #####
"""
Digital Being Server implementation.
Implements:
 - /oauth_callback endpoint to finalize OAuth after user is redirected back
 - WebSocket commands for front-end
 - Pause/Resume logic
 - Checking is_configured for front-end
 - [ADDED] Returning 'enabled' status for each loaded activity
"""

import asyncio
import json
import logging
import http
import mimetypes
from pathlib import Path
from typing import Dict, Any, Set, Union, Tuple
from datetime import datetime

import websockets
from websockets.server import serve
from websockets.legacy.server import WebSocketServerProtocol
from aiohttp import web

# Initialize the logger with logging.INFO before importing other modules
# to make sure INFO level logs are printed (Otherwise it gets set to WARN)
logging.basicConfig(level=logging.INFO)

# Import api_manager at top-level (not again inside any function)
from framework.api_management import api_manager
from framework.main import DigitalBeing
from framework.skill_config import DynamicComposioSkills
from skills.skill_chat import chat_skill

logger = logging.getLogger(__name__)


class DigitalBeingServer:
    """Server for the Digital Being application."""

    def __init__(self, host: str = "0.0.0.0", port: int = 8000):
        self.host = host
        self.port = port
        self.clients: Set[WebSocketServerProtocol] = set()
        self.being = DigitalBeing()
        self.being_state: Dict[str, Any] = {}
        self.static_path = Path(__file__).parent / "static"

        # Additional flags for running/paused
        self.running = False
        self.paused = False

    async def initialize(self):
        """Initialize the digital being and start periodic updates."""
        logger.info("Initializing Digital Being...")
        self.being.initialize()  # load config, etc.

        self.running = True  # default "running"
        asyncio.create_task(self._periodic_state_update())
        asyncio.create_task(self._run_being_loop())

    async def _run_being_loop(self):
        """Main loop that calls the being's activities if running & not paused."""
        while True:
            try:
                if not self.running:
                    await asyncio.sleep(2)
                    continue

                if self.paused:
                    await asyncio.sleep(2)
                    continue

                if not self.being.is_configured():
                    # If not configured, do nothing in the main loop
                    await asyncio.sleep(2)
                    continue

                # Single-step approach for selecting an activity
                current_activity = self.being.activity_selector.select_next_activity()
                if current_activity:
                    logger.info(
                        f"Executing activity: {current_activity.__class__.__name__}"
                    )
                    result = await self.being.execute_activity(current_activity)
                    if result and result.success:
                        self.being_state["last_activity"] = {
                            "name": current_activity.__class__.__name__,
                            "timestamp": datetime.now().isoformat(),
                            "success": True,
                        }
                    else:
                        self.being_state["last_activity"] = {
                            "name": current_activity.__class__.__name__,
                            "timestamp": datetime.now().isoformat(),
                            "success": False,
                            "error": (result.error if result else "Unknown error"),
                        }
                    await self.broadcast_state()

                self.being.state.update()
                self.being.memory.persist()
                await asyncio.sleep(5)

            except Exception as e:
                logger.error(f"Error in being loop: {e}")
                await asyncio.sleep(10)

    async def _periodic_state_update(self):
        """Periodically update and broadcast the being's state every second."""
        while True:
            try:
                current_state = self.being.state.get_current_state()
                # Provide 'configured' and 'paused' status
                current_state["configured"] = self.being.is_configured()
                current_state["paused"] = self.paused

                if current_state != self.being_state:
                    self.being_state = current_state
                    await self.broadcast_state()
                await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"Error in periodic state update: {e}")
                await asyncio.sleep(5)

    async def register(self, websocket: WebSocketServerProtocol):
        self.clients.add(websocket)
        logger.info(f"Client connected. Total clients: {len(self.clients)}")

        # Send the current state right away
        await websocket.send(
            json.dumps({"type": "state_update", "data": self.being_state})
        )

    async def unregister(self, websocket: WebSocketServerProtocol):
        self.clients.discard(websocket)
        logger.info(f"Client disconnected. Total clients: {len(self.clients)}")

    async def serve_static_file(
        self, path: str, request_headers: Dict
    ) -> Union[Tuple[http.HTTPStatus, list, bytes], None]:
        try:
            if path == "/ws":
                return None

            if path.startswith("/oauth_callback"):
                return await self.handle_oauth_http_callback(path)

            if not isinstance(path, str):
                return None

            request_path = "/" + path.lstrip("/")
            if request_path == "/":
                request_path = "/index.html"

            if request_path == "/ws":
                if (
                    request_headers.get("Upgrade", "").lower() == "websocket"
                    and request_headers.get("Connection", "").lower() == "upgrade"
                ):
                    logger.info("Valid WebSocket upgrade request")
                    return None
                logger.warning("Invalid WebSocket request")
                return (
                    http.HTTPStatus.BAD_REQUEST,
                    [("Content-Type", "text/plain")],
                    b"Invalid WebSocket request",
                )

            file_path = self.static_path / request_path.lstrip("/")
            if not file_path.exists() or not file_path.is_file():
                logger.warning(f"File not found: {file_path}")
                return (
                    http.HTTPStatus.NOT_FOUND,
                    [("Content-Type", "text/plain")],
                    b"404 Not Found",
                )

            content_type, _ = mimetypes.guess_type(str(file_path))
            if not content_type:
                content_type = "application/octet-stream"

            content = file_path.read_bytes()
            return (
                http.HTTPStatus.OK,
                [
                    ("Content-Type", content_type),
                    ("Cache-Control", "public, max-age=3600"),
                ],
                content,
            )

        except Exception as e:
            logger.error(f"Error serving {path}: {e}")
            return (
                http.HTTPStatus.INTERNAL_SERVER_ERROR,
                [("Content-Type", "text/plain")],
                b"Internal Server Error",
            )

    async def handle_oauth_http_callback(self, path: str):
        """
        Handle GET /oauth_callback?status=success&connectedAccountId=...&appName=...
        Then finalize or store connection info, auto-fetch & register app actions,
        and finally redirect to "/".
        """
        from urllib.parse import urlparse, parse_qs

        parsed = urlparse(path)
        query = parse_qs(parsed.query)

        status = query.get("status", [""])[0]
        connected_account_id = query.get("connectedAccountId", [None])[0]
        app_name = query.get("appName", [""])[0]
        code = query.get("code", [None])[0]

        if not connected_account_id:
            logger.error("Missing connectedAccountId param in /oauth_callback")
            body = b"Missing connectedAccountId param"
            return (
                http.HTTPStatus.BAD_REQUEST,
                [("Content-Type", "text/plain")],
                body,
            )

        logger.info(
            f"OAuth callback success for app={app_name}, connectedAccountId={connected_account_id}, status={status}"
        )

        try:
            if code:
                finalize_result = (
                    await api_manager.composio_manager.handle_oauth_callback(
                        connected_account_id, code
                    )
                )
                logger.info(f"handle_oauth_callback returned: {finalize_result}")
            else:
                if app_name:
                    api_manager.composio_manager.mark_app_connected_without_code(
                        app_name, connected_account_id
                    )

            if app_name:
                logger.info(
                    f"Auto-fetching actions for newly connected app: {app_name}"
                )
                actions_result = await api_manager.list_actions_for_app(app_name)
                if actions_result.get("success"):
                    actions = actions_result.get("actions", [])
                    if actions:
                        logger.info(
                            f"Discovered {len(actions)} actions for {app_name}, registering now..."
                        )
                        DynamicComposioSkills.register_composio_actions(
                            app_name, actions
                        )
                    else:
                        logger.warning(f"No actions found for {app_name}.")
                else:
                    logger.warning(
                        f"Failed to fetch actions for {app_name}: {actions_result.get('error')}"
                    )

        except Exception as e:
            logger.error(
                f"Error finalizing/fetching actions for {app_name}: {e}", exc_info=True
            )

        redirect_body = b'<html><head><meta http-equiv="refresh" content="0;URL=\'/\'" /></head><body>Redirecting...</body></html>'
        return (
            http.HTTPStatus.OK,
            [("Content-Type", "text/html")],
            redirect_body,
        )

    async def handle_websocket(self, websocket: WebSocketServerProtocol, path: str):
        """Handle WebSocket connections at /ws."""
        try:
            if path != "/ws":
                logger.warning(f"Invalid WebSocket path: {path}")
                await websocket.close(code=1008, reason="Invalid path")
                return

            await self.register(websocket)
            try:
                async for message in websocket:
                    try:
                        data = json.loads(message)
                        await self.process_message(websocket, data)
                    except json.JSONDecodeError:
                        logger.error(f"Invalid JSON: {message}")
                    except Exception as e:
                        logger.error(f"Error processing WS message: {e}")
            except websockets.ConnectionClosed:
                logger.info("WebSocket closed normally")
            except Exception as e:
                logger.error(f"WebSocket error: {e}")
        finally:
            await self.unregister(websocket)

    async def process_message(
        self, websocket: WebSocketServerProtocol, data: Dict[str, Any]
    ):
        try:
            message_type = data.get("type")
            if not message_type:
                logger.warning("No message type in WS data!")
                return

            if message_type == "get_state":
                await websocket.send(
                    json.dumps({"type": "state_update", "data": self.being_state})
                )
            elif message_type == "command":
                command = data.get("command")
                if command:
                    resp = await self.handle_command(command, data.get("params", {}))
                    await websocket.send(
                        json.dumps(
                            {
                                "type": "command_response",
                                "command": command,
                                "response": resp,
                            }
                        )
                    )
        except Exception as e:
            logger.error(f"Error in process_message: {e}")
            await websocket.send(json.dumps({"type": "error", "message": str(e)}))

    async def handle_command(
        self, command: str, params: Dict[str, Any]
    ) -> Dict[str, Any]:
        logger.debug(f"handle_command: {command}, params={params}")
        try:
            if command == "pause":
                self.paused = True
                return {"success": True, "message": "Digital Being is paused."}
            elif command == "resume":
                self.paused = False
                return {"success": True, "message": "Digital Being resumed."}
            elif command == "stop_loop":
                self.running = False
                return {"success": True, "message": "Core loop stopped."}
            elif command == "start_loop":
                self.running = True
                return {"success": True, "message": "Core loop started."}
            elif command == "run_activity":
                activity_key = params.get("activity_key")
                if not activity_key:
                    return {"success": False, "error": "Missing activity_key parameter"}
                
                try:
                    # Get the activity class from the activity selector
                    activity_class = self.being.activity_selector.get_activity_class(activity_key)
                    if not activity_class:
                        return {"success": False, "error": f"Activity '{activity_key}' not found"}
                    
                    # Create an instance and execute it
                    activity = activity_class()
                    result = await self.being.execute_activity(activity)
                    
                    if result and result.success:
                        return {"success": True, "message": f"Activity '{activity_key}' executed successfully"}
                    else:
                        error_msg = result.error if result else "Unknown error"
                        return {"success": False, "error": f"Activity execution failed: {error_msg}"}
                except Exception as e:
                    logger.error(f"Error running activity {activity_key}: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "initiate_oauth":
                app_name = params.get("app_name")
                base_url = params.get("base_url", "http://localhost:8000")
                if not app_name:
                    return {"success": False, "error": "Missing app_name"}
                redirect_url = f"{base_url}/oauth_callback"
                try:
                    result = await api_manager.composio_manager.initiate_oauth_flow(
                        app_name, redirect_url
                    )
                    return result
                except Exception as e:
                    logger.error(f"init_oauth error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "get_composio_integrations":
                try:
                    integrations = (
                        await api_manager.composio_manager.list_available_integrations()
                    )
                    return {"success": True, "composio_integrations": integrations}
                except Exception as e:
                    logger.error(f"Error get_composio_integrations: {e}")
                    return {
                        "success": False,
                        "error": str(e),
                        "composio_integrations": [],
                    }

            elif command == "get_api_key_status":
                skills_status = await api_manager.get_skill_status()
                return {"success": True, "skills": skills_status}

            elif command == "configure_api_key":
                skill_name = params.get("skill_name")
                key_name = params.get("key_name")
                api_key_value = params.get("api_key")
                if not all([skill_name, key_name, api_key_value]):
                    return {"success": False, "message": "Missing required params"}
                try:
                    result = await api_manager.set_api_key(
                        skill_name, key_name, api_key_value
                    )
                    return result
                except Exception as e:
                    return {"success": False, "message": str(e)}

            elif command == "get_system_status":
                memory_stats = {
                    "short_term_count": len(self.being.memory.short_term_memory),
                    "long_term_count": sum(
                        len(x) for x in self.being.memory.long_term_memory.values()
                    ),
                    "total_activities": self.being.memory.get_activity_count(),
                }
                current_state = self.being.state.get_current_state()
                is_config = self.being.is_configured()

                return {
                    "success": True,
                    "memory": memory_stats,
                    "state": current_state,
                    "is_configured": is_config,
                    "config": self.being.configs,
                }

            elif command == "get_activities":
                # Return loaded activities with 'enabled' status from activity_constraints
                acts = self.being.activity_loader.get_all_activities()
                info = {}

                activities_config = {}
                if (
                    "activity_constraints" in self.being.configs
                    and "activities_config"
                    in self.being.configs["activity_constraints"]
                ):
                    activities_config = self.being.configs["activity_constraints"][
                        "activities_config"
                    ]

                for module_name, cls in acts.items():
                    class_name = cls.__name__
                    is_enabled = True
                    if class_name in activities_config:
                        is_enabled = bool(
                            activities_config[class_name].get("enabled", True)
                        )

                    info[module_name] = {
                        "name": class_name,
                        "energy_cost": cls.energy_cost,
                        "cooldown": cls.cooldown,
                        "required_skills": cls.required_skills,
                        "last_execution": (
                            cls.last_execution.isoformat()
                            if cls.last_execution
                            else None
                        ),
                        "enabled": is_enabled,
                    }
                return {"success": True, "activities": info}

            elif command == "get_config":
                return {"success": True, "config": self.being.configs}

            elif command == "update_config":
                section = params.get("section")
                key = params.get("key")
                value = params.get("value")

                if not section or not key:
                    return {
                        "success": False,
                        "message": "Both 'section' and 'key' are required.",
                    }

                # Map sections to config files
                section_to_file = {
                    "character_config": "character_config.json",
                    "skills_config": "skills_config.json",
                    "activity_constraints": "activity_constraints.json",
                }

                config_file_name = section_to_file.get(section)
                if not config_file_name:
                    return {
                        "success": False,
                        "message": f"Unknown configuration section: {section}",
                    }

                config_path = Path(self.being.config_path) / config_file_name

                try:
                    if config_path.exists():
                        with open(config_path, "r") as f:
                            current_config = json.load(f)
                    else:
                        current_config = {}
                except json.JSONDecodeError as je:
                    logger.error(f"Failed to parse {config_file_name}: {je}")
                    return {
                        "success": False,
                        "message": f"Invalid JSON format in {config_file_name}.",
                    }
                except Exception as e:
                    logger.error(f"Error loading {config_file_name}: {e}")
                    return {
                        "success": False,
                        "message": f"Error loading {config_file_name}.",
                    }

                # Update the config
                current_config[key] = value

                # Write back
                try:
                    with open(config_path, "w") as f:
                        json.dump(current_config, f, indent=2)
                except Exception as e:
                    logger.error(f"Failed to write to {config_file_name}: {e}")
                    return {
                        "success": False,
                        "message": f"Failed to write to {config_file_name}.",
                    }

                # Update in-memory
                self.being.configs[section][key] = value
                logger.info(f"Updated config: [{section}] {key} = {value}")

                return {
                    "success": True,
                    "message": f"Configuration '{key}' updated successfully.",
                }

            elif command == "get_activity_history":
                limit = params.get("limit", 10)
                offset = params.get("offset", 0)
                recents = self.being.memory.get_recent_activities(limit=limit, offset=offset)
                total = self.being.memory.get_activity_count()
                return {
                    "success": True,
                    "activities": recents,
                    "has_more": total > (offset + limit),
                    "total": total,
                }

            elif command == "get_composio_app_actions":
                app_name = params.get("app_name")
                result = await api_manager.list_actions_for_app(app_name)
                if result.get("success"):
                    DynamicComposioSkills.register_composio_actions(
                        app_name, result.get("actions", [])
                    )
                return result

            elif command == "get_all_skills":
                config_skills = self.being.configs.get("skills_config", {})
                manual_skills_list = []
                for skill_name, skill_info in config_skills.items():
                    if not isinstance(skill_info, dict):
                        logger.debug(
                            f"Skipping non-dict skill config: {skill_name} => {skill_info}"
                        )
                        continue
                    manual_skills_list.append(
                        {
                            "skill_name": skill_name,
                            "enabled": bool(skill_info.get("enabled", False)),
                            "metadata": skill_info,
                        }
                    )

                dynamic_skills = DynamicComposioSkills.get_all_dynamic_skills()
                all_skills = manual_skills_list + dynamic_skills
                return {"success": True, "skills": all_skills}

            elif command == "get_activity_code":
                from framework.activity_loader import read_activity_code
                activity_name = params.get("activity_name")
                code_str = read_activity_code(activity_name)
                if code_str is None:
                    return {
                        "success": False,
                        "message": f"Could not read code for {activity_name}",
                    }
                return {"success": True, "code": code_str}

            elif command == "save_activity_code":
                from framework.activity_loader import write_activity_code
                activity_name = params.get("activity_name")
                new_code = params.get("new_code")
                ok = write_activity_code(activity_name, new_code)
                if not ok:
                    return {"success": False, "message": "Failed to save code"}
                self.being.activity_loader.reload_activities()
                return {"success": True, "message": "Code updated and reloaded"}

            elif command == "save_onboarding_data":
                """
                Expects 'character', 'skills', and 'constraints' from front-end.
                The 'skills' object may have e.g.:
                  {
                    "lite_llm": {
                      "enabled": true,
                      "model_name": "anthropic/claude-3-5-haiku-20241022",
                      "required_api_keys": ["LITELLM"],
                      "provided_api_key": "sk-1234abcd..."
                    },
                    "default_llm_skill": "lite_llm"
                  }
                """
                try:
                    char_data = params.get("character", {})
                    skills_data = params.get("skills", {})
                    constraints_data = params.get("constraints", {})

                    char_path = Path(self.being.config_path) / "character_config.json"
                    skill_path = Path(self.being.config_path) / "skills_config.json"
                    actc_path = Path(self.being.config_path) / "activity_constraints.json"

                    existing_char = {}
                    existing_skills = {}
                    existing_actc = {}

                    # Load existing JSON
                    if char_path.exists():
                        existing_char = json.loads(char_path.read_text(encoding="utf-8"))
                    if skill_path.exists():
                        existing_skills = json.loads(skill_path.read_text(encoding="utf-8"))
                    if actc_path.exists():
                        existing_actc = json.loads(actc_path.read_text(encoding="utf-8"))

                    # Merge the new data
                    existing_char.update(char_data)
                    existing_skills.update(skills_data)
                    for k, v in constraints_data.items():
                        existing_actc[k] = v

                    # Possibly set "setup_complete"
                    existing_char["setup_complete"] = True

                    # If user provided an API key for any skill, store it with secret manager
                    for skill_name, skill_info in skills_data.items():
                        if not isinstance(skill_info, dict):
                            continue
                        maybe_key = skill_info.get("provided_api_key")
                        if maybe_key:
                            required_keys = skill_info.get("required_api_keys", [])
                            if required_keys:
                                main_key = required_keys[0]
                                await api_manager.set_api_key(skill_name, main_key, maybe_key)

                            # Remove 'provided_api_key' from final JSON if you prefer
                            if "provided_api_key" in existing_skills[skill_name]:
                                del existing_skills[skill_name]["provided_api_key"]

                    # Save the updated JSON
                    char_path.write_text(json.dumps(existing_char, indent=2), encoding="utf-8")
                    skill_path.write_text(json.dumps(existing_skills, indent=2), encoding="utf-8")
                    actc_path.write_text(json.dumps(existing_actc, indent=2), encoding="utf-8")

                    # Reload in memory
                    self.being.configs["character_config"] = existing_char
                    self.being.configs["skills_config"] = existing_skills
                    self.being.configs["activity_constraints"] = existing_actc

                    return {"success": True, "message": "Onboarding data saved."}

                except Exception as e:
                    logger.error(f"Error saving onboarding data: {e}", exc_info=True)
                    return {"success": False, "message": str(e)}

            elif command == "get_auth_schemes":
                app_name = params.get("app_name")
                if not app_name:
                    return {"success": False, "error": "Missing app_name"}
                try:
                    result = await api_manager.get_auth_schemes(app_name)
                    return result
                except Exception as e:
                    logger.error(f"get_auth_schemes error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "initiate_api_key_connection":
                app_name = params.get("app_name")
                connection_params = params.get("connection_params")
                if not app_name or not connection_params:
                    return {"success": False, "error": "Missing app_name or connection_params"}
                try:
                    result = await api_manager.initiate_api_key_connection(app_name, connection_params)
                    return result
                except Exception as e:
                    logger.error(f"initiate_api_key_connection error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "initiate_oauth_with_params":
                app_name = params.get("app_name")
                base_url = params.get("base_url", "http://localhost:8000")
                connection_params = params.get("connection_params")
                if not app_name or not connection_params:
                    return {"success": False, "error": "Missing app_name or connection_params"}
                redirect_url = f"{base_url}/oauth_callback"
                try:
                    result = await api_manager.composio_manager.initiate_oauth_with_params(
                        app_name, redirect_url, connection_params
                    )
                    return result
                except Exception as e:
                    logger.error(f"initiate_oauth_with_params error: {e}")
                    return {"success": False, "error": str(e)}

            elif command == "get_chat_history":
                # Retrieve the subset of memory entries relating to chat
                all_entries = self.being.memory.get_recent_activities(limit=50)
                chat_entries = [entry for entry in all_entries if "chat" in entry.get("activity_type", "").lower()]
                return {"success": True, "chat_history": chat_entries}

            elif command == "send_chat_message":
                from datetime import datetime
                user_message = params.get("message", "")
                if not user_message:
                    return {"success": False, "error": "No message provided"}
                
                try:
                    timestamp = datetime.now().isoformat()
                    # Store the user's message in memory with pending status
                    self.being.memory.store_activity_result({
                        "timestamp": timestamp,
                        "activity_type": "UserChatMessage",
                        "result": {
                            "success": True,
                            "data": {
                                "sender": "User",
                                "message": user_message,
                                "status": "pending"
                            }
                        }
                    })
                    
                    logger.info(f"Successfully stored chat message: {user_message}")
                    return {"success": True, "message": "Chat message received"}
                except Exception as e:
                    logger.error(f"Error storing chat message: {e}", exc_info=True)
                    return {"success": False, "error": f"Failed to store message: {str(e)}"}

        except Exception as e:
            logger.error(f"handle_command {command} error: {e}")
            return {"success": False, "message": str(e)}

        return {"success": False, "message": "Unknown command"}

    async def broadcast_state(self):
        """Broadcast the current being_state to all connected WebSocket clients."""
        if not self.clients:
            return
        message = json.dumps({"type": "state_update", "data": self.being_state})
        disconnected_clients = set()
        for client in self.clients:
            try:
                await client.send(message)
            except websockets.ConnectionClosed:
                logger.info("Client disconnected during broadcast")
                disconnected_clients.add(client)
            except Exception as e:
                logger.error(f"Error broadcasting to client: {e}")
                disconnected_clients.add(client)

        for dc in disconnected_clients:
            await self.unregister(dc)

    async def start_server(self):
        """Start the server using websockets.serve()."""
        try:
            await self.initialize()
            async with serve(
                self.handle_websocket,
                self.host,
                self.port,
                process_request=self.serve_static_file,
            ):
                logger.info(f"Server started on ws://{self.host}:{self.port}")
                await asyncio.Future()  # run forever
        except Exception as e:
            logger.error(f"Failed to start server: {e}")
            raise


if __name__ == "__main__":
    server = DigitalBeingServer()
    asyncio.run(server.start_server())

